# Chunking é·ç§»ä»»å‹™æ¸…å–®

**å‰µå»ºæ—¥æœŸ**: 2025-11-25
**åƒè€ƒæ–‡æª”**: `docs/migration_evaluation_report.md`

---

## æ ¸å¿ƒè¨­è¨ˆç¢ºèª

### AI åˆ†å¡Šè¼¸å‡ºæ ¼å¼
```json
{
  "logical_chunks": [
    {
      "chunk_id": 1,
      "start_id": "L001",
      "end_id": "L010",
      "type": "header",
      "summary": "å€å¡Šæ‘˜è¦"
    }
  ]
}
```

âœ… **åªè¿”å›è¡Œè™Ÿåº§æ¨™** (`start_id`, `end_id`)
âŒ **ä¸è¿”å›åŸå§‹æ–‡æœ¬å…§å®¹** (å¾ `line_mapping` æå–)

---

## Phase 0: æ¬„ä½æ¸…ç† âœ… å·²å®Œæˆ

- [x] Prompt æ¬„ä½æ¸…ç† (`document_prompts.py`)
- [x] æ¨¡å‹æ¬„ä½æ¸…ç† (`ai_models_simplified.py`)
- [x] Fallback é‚è¼¯ç§»é™¤ (`entity_extraction_service.py`)
- [x] ç›¸é—œ Prompt æ›´æ–° (`mongodb_prompts.py`, `document_detail_query_handler.py`)

---

## Phase 1: å‰è™•ç†æ”¹é€  âœ… å·²å®Œæˆ

### 1.1 è¡Œè™Ÿæ¨™è¨˜æœå‹™
- [x] æ–°å¢ `line_marker_service.py`
- [x] å¯¦ç¾ `add_line_markers(text, global_start)` å‡½æ•¸
- [x] è¿”å› `(marked_text, line_mapping)` å…ƒçµ„

### 1.2 æ–‡æª”é¡å‹è™•ç†
- [x] PDF/DOCX/TXT: æå–æ–‡å­—å¾Œæ³¨å…¥è¡Œè™Ÿ
- [x] åœ–ç‰‡: åœ¨ AI åˆ†ææ™‚ç›´æ¥è¼¸å‡ºå¸¶è¡Œè™Ÿçš„ OCR çµæœ

### 1.3 MongoDB å„²å­˜
- [x] `document_models.py` æ–°å¢ `line_mapping` æ¬„ä½
- [x] å„²å­˜è¡Œè™Ÿåˆ°å­—ç¬¦ä½ç½®çš„æ˜ å°„

### 1.4 é•·æ–‡æª”åˆ†æ‰¹
- [x] å¯¦ç¾é•·åº¦åˆ¤æ–· (< 10K ç›´æ¥ï¼Œâ‰¥ 10K åˆ†æ‰¹)
- [x] PDF/Word: æŒ‰é åˆ†æ‰¹ (5 é /æ‰¹)
- [x] ç´”æ–‡å­—: æŒ‰å­—æ•¸åˆ†æ‰¹ (10K å­—å…ƒ/æ‰¹)
- [x] è·¨æ‰¹æ¬¡è¡Œè™Ÿé€£çºŒ

**å·²å®Œæˆæª”æ¡ˆ**:
- æ–°å¢: `app/services/document/line_marker_service.py`
- ä¿®æ”¹: `app/models/document_models.py`

### 1.5 è™•ç†æµç¨‹æ•´åˆ âœ… å·²å®Œæˆ
- [x] ä¿®æ”¹ `document_tasks_service.py` æ•´åˆè¡Œè™Ÿæ¨™è¨˜æœå‹™
- [x] ä¿®æ”¹ `crud_documents.py` æ”¯æ´å„²å­˜ `line_mapping`
- [x] `_process_text_document()` åœ¨æ–‡å­—æå–å¾Œè‡ªå‹•ç”Ÿæˆè¡Œè™Ÿæ˜ å°„
- [x] `trigger_document_analysis()` åŒæ­¥æ”¯æ´è¡Œè™Ÿæ¨™è¨˜

**æ•´åˆæª”æ¡ˆ**:
- ä¿®æ”¹: `app/services/document/document_tasks_service.py`
- ä¿®æ”¹: `app/crud/crud_documents.py`

**API ç«¯é»è¡Œç‚º**: ç„¡è®ŠåŒ– (å…§éƒ¨è‡ªå‹•è™•ç†)
**å‰ç«¯ä¿®æ”¹éœ€æ±‚**: Phase 1 ç„¡éœ€ä¿®æ”¹

---

## Phase 2: Prompt ä¿®æ”¹ âœ… å·²å®Œæˆ

### 2.1 ä¿®æ”¹ç¾æœ‰ Prompt (åœ¨ç¾æœ‰åŸºç¤ä¸Šæ“´å±•)
- [x] ä¿®æ”¹ `get_image_analysis_prompt()` - æ·»åŠ  `logical_chunks` è¼¸å‡º
- [x] ä¿®æ”¹ `get_text_analysis_prompt()` - æ·»åŠ  `logical_chunks` è¼¸å‡º
- [x] è¼¸å‡ºæ ¼å¼: åœ¨ç¾æœ‰ JSON ä¸­æ–°å¢ `logical_chunks` æ¬„ä½
- [x] åªè¼¸å‡ºåº§æ¨™ (`start_id`, `end_id`)ï¼Œä¸è¼¸å‡ºåŸæ–‡

### 2.2 æ–°å¢è¼¸å‡ºæ¬„ä½
```json
{
  // ... ç¾æœ‰æ¬„ä½ä¿æŒä¸è®Š ...
  "logical_chunks": [
    {
      "chunk_id": 1,
      "start_id": "L001",
      "end_id": "L010",
      "type": "header|paragraph|list|table|code_block",
      "summary": "å€å¡Šæ‘˜è¦ (1-2å¥)"
    }
  ]
}
```

### 2.3 åˆ†å¡ŠæŒ‡å°åŸå‰‡ (åŠ å…¥ Prompt)
- [x] ä¾æ“šèªç¾©å®Œæ•´æ€§åˆ†çµ„
- [x] ä¸åˆ‡æ–·åˆ—è¡¨ã€è¡¨æ ¼ã€ç¨‹å¼ç¢¼å€å¡Š
- [x] ç™¼ç¥¨/æ”¶æ“š: æŒ‰è¦–è¦ºæ’ç‰ˆåˆ†å¡Š (è¡¨é ­ã€å•†å“åˆ—è¡¨ã€åˆè¨ˆ)
- [x] PDF/æ–‡æª”: æŒ‰èªç¾©æ®µè½åˆ†å¡Š
- [x] **ç²’åº¦æ§åˆ¶**: æ·»åŠ  10-30 è¡Œ/chunk æŒ‡å°ï¼Œç›®æ¨™ 8-20 chunks/æ–‡æª” (2025-11-25)

### 2.4 é•·æ–‡æª”åˆ†æ‰¹è™•ç†
- [ ] è¼¸å…¥æ™‚å‘ŠçŸ¥æ¨¡å‹ã€Œé€™æ˜¯ç¬¬ N/M æ‰¹ï¼Œè¡Œè™Ÿç¯„åœ L051-L100ã€(Phase 3 å¯¦ç¾)
- [ ] è™•ç†æ‰¹æ¬¡é‚Šç•Œæ¨™è¨˜ (å¯é¸)

### 2.5 AI æ¨¡å‹å’Œè™•ç†æµç¨‹æ•´åˆ
- [x] æ–°å¢ `LogicalChunk` Pydantic æ¨¡å‹
- [x] æ›´æ–° `AIImageAnalysisOutput` æ·»åŠ  `logical_chunks` æ¬„ä½
- [x] æ›´æ–° `AITextAnalysisOutput` æ·»åŠ  `logical_chunks` æ¬„ä½
- [x] ä¿®æ”¹ `_process_text_document()` å‚³éå¸¶è¡Œè™Ÿæ–‡æœ¬çµ¦ AI
- [x] ä¿®æ”¹ `trigger_document_analysis()` å‚³éå¸¶è¡Œè™Ÿæ–‡æœ¬çµ¦ AI

### 2.6 æ¸¬è©¦é©—è­‰
- [ ] è¼¸å‡ºç©©å®šæ€§æ¸¬è©¦
- [ ] è¡Œè™Ÿæ ¼å¼é©—è­‰ (L001, L002...)
- [ ] ç¢ºä¿ç¾æœ‰æ¬„ä½ä¸å—å½±éŸ¿

**å·²å®Œæˆæª”æ¡ˆ**:
- ä¿®æ”¹: `app/services/ai/prompts/document_prompts.py` (å…©å€‹ç¾æœ‰å‡½æ•¸)
- ä¿®æ”¹: `app/models/ai_models_simplified.py` (æ–°å¢ LogicalChunk, æ›´æ–°è¼¸å‡ºæ¨¡å‹)
- ä¿®æ”¹: `app/services/document/document_tasks_service.py` (å‚³éå¸¶è¡Œè™Ÿæ–‡æœ¬)

---

## Phase 3: å‘é‡åŒ–é‡æ§‹ âœ… å·²å®Œæˆ

### 3.0 å‘é‡åŒ–æ¨¡å‹ç‰¹æ€§ (2025-11-25 ç¢ºèª)

| ç‰¹æ€§ | å€¼ | å½±éŸ¿ |
|------|---|------|
| **æ¨¡å‹åç¨±** | `paraphrase-multilingual-mpnet-base-v2` | å¤šèªè¨€æ”¯æŒ |
| **å‘é‡ç¶­åº¦** | 768 | æ¨™æº–ç¶­åº¦ |
| **æœ€å¤§è¼¸å…¥é•·åº¦** | **512 å­—ç¬¦** | âš ï¸ é—œéµé™åˆ¶ |
| **ç¾æœ‰ chunk å¤§å°** | 462 å­—ç¬¦ | é ç•™ 50 å­—ç¬¦é‡ç–Š |

### 3.1 å‘é‡åŒ–ç­–ç•¥è¨­è¨ˆ âœ… å·²ç¢ºå®š

#### æ ¸å¿ƒæ±ºç­–

| æ±ºç­–é … | é¸æ“‡ | ç†ç”± |
|--------|------|------|
| **çŸ­ chunks åˆä½µ** | âŒ ä¸åšå¾Œè™•ç†åˆä½µ | å®Œå…¨ä¿¡ä»» AI èªç¾©åˆ†çµ„ |
| **å‘é‡åŒ–ç­–ç•¥** | âœ… æ™ºèƒ½å­åˆ†å¡Š | ç¢ºä¿æ‰€æœ‰å…§å®¹éƒ½è¢«å‘é‡åŒ– |
| **æ··åˆå¢å¼·** | âœ… æ¢ä»¶æ€§ä½¿ç”¨ | çŸ­ chunks ä½¿ç”¨ï¼Œé•· chunks ä¸ç”¨ |

#### æ™ºèƒ½å­åˆ†å¡Šç­–ç•¥

æ ¹æ“š chunk åŸæ–‡é•·åº¦ï¼Œé¸æ“‡ä¸åŒçš„å‘é‡åŒ–ç­–ç•¥ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ™ºèƒ½å­åˆ†å¡Šå‘é‡åŒ–ç­–ç•¥ (512 å­—ç¬¦é™åˆ¶)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  åŸæ–‡é•·åº¦åˆ¤æ–·                                                â”‚
â”‚       â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â‰¤ 350 å­—ç¬¦      â”‚ 351-480 å­—ç¬¦    â”‚ > 480 å­—ç¬¦        â”‚ â”‚
â”‚  â”‚     â†“           â”‚      â†“          â”‚      â†“            â”‚ â”‚
â”‚  â”‚ æ··åˆå¢å¼·        â”‚ åªç”¨åŸæ–‡        â”‚ å­åˆ†å¡Š            â”‚ â”‚
â”‚  â”‚ [Summary]+      â”‚ (å®Œæ•´å‘é‡åŒ–)    â”‚ (åˆ‡åˆ†æˆå¤šå€‹å­å¡Š)  â”‚ â”‚
â”‚  â”‚ [Content]       â”‚                 â”‚                   â”‚ â”‚
â”‚  â”‚     â†“           â”‚      â†“          â”‚      â†“            â”‚ â”‚
â”‚  â”‚  1 å‘é‡         â”‚   1 å‘é‡        â”‚   N å‘é‡          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  âœ… ä¿è­‰ï¼šæ‰€æœ‰å…§å®¹éƒ½æœƒè¢«å‘é‡åŒ–ï¼Œä¸ä¸Ÿå¤±ä»»ä½•è³‡è¨Š               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### é…ç½®åƒæ•¸

```python
# æ–°å¢é…ç½®é … (config.py)
EMBEDDING_MAX_LENGTH = 512           # æ¨¡å‹æœ€å¤§è¼¸å…¥é•·åº¦
CHUNK_HYBRID_THRESHOLD = 350         # ä½æ–¼æ­¤é•·åº¦ä½¿ç”¨æ··åˆå¢å¼·
CHUNK_SAFE_LENGTH = 480              # å–®å‘é‡æœ€å¤§åŸæ–‡é•·åº¦
SUB_CHUNK_OVERLAP = 50               # å­åˆ†å¡Šé‡ç–Šå­—ç¬¦æ•¸
```

#### å‘é‡åŒ–å…§å®¹æ ¼å¼

| æƒ…æ³ | åŸæ–‡é•·åº¦ | å‘é‡åŒ–å…§å®¹ | å‘é‡æ•¸ |
|------|----------|-----------|--------|
| çŸ­ chunk | â‰¤ 350 å­—ç¬¦ | `[Summary]: {summary}\n[Content]: {raw_text}` | 1 |
| ä¸­ç­‰ chunk | 351-480 å­—ç¬¦ | `{raw_text}` (å®Œæ•´åŸæ–‡) | 1 |
| é•· chunk | > 480 å­—ç¬¦ | å­åˆ†å¡Š (æ¯å¡Š ~450 å­—ç¬¦ï¼Œ50 å­—ç¬¦é‡ç–Š) | N |

### 3.2 å¯¦ç¾ä»»å‹™æ¸…å–®

#### 3.2.1 åŸæ–‡æå–å‡½æ•¸ âœ…
- [x] `extract_text_by_line_range()` å·²å­˜åœ¨æ–¼ `line_marker_service.py`
- [x] è™•ç†è¡Œè™Ÿç¯„åœæå–é‚è¼¯

#### 3.2.2 æ™ºèƒ½å‘é‡åŒ–å‡½æ•¸ âœ…
- [x] åœ¨ `line_marker_service.py` ä¸­å¯¦ç¾ (é¿å…å¾ªç’°ä¾è³´)
- [x] å¯¦ç¾ `process_logical_chunk_for_vectorization()` å‡½æ•¸
- [x] å¯¦ç¾ `smart_split_text()` å­åˆ†å¡Šå‡½æ•¸
- [x] æ··åˆå¢å¼·ç›´æ¥åœ¨ `process_logical_chunk_for_vectorization()` ä¸­å¯¦ç¾

#### 3.2.3 ä¿®æ”¹å‘é‡åŒ–ä¸»æµç¨‹ âœ…
- [x] ä¿®æ”¹ `semantic_summary_service.py`
- [x] æ–°å¢ `_create_chunk_vectors_from_logical_chunks()` æ–¹æ³•
- [x] ä½¿ç”¨ AI è¿”å›çš„ `logical_chunks` å–ä»£å›ºå®šåˆ†å¡Š
- [x] ä¿ç•™ Document Summary Vector é‚è¼¯ä¸è®Š
- [x] å¯¦ç¾ fallback åˆ°å›ºå®šå¤§å°åˆ†å¡Š (ç•¶ AI chunks ä¸å¯ç”¨æ™‚)

#### 3.2.4 ChromaDB Metadata æ“´å±• âœ…
- [x] æ–°å¢ `start_line` æ¬„ä½ (ä¾‹å¦‚ "L001")
- [x] æ–°å¢ `end_line` æ¬„ä½ (ä¾‹å¦‚ "L010")
- [x] æ–°å¢ `chunk_type` æ¬„ä½ (ä¾‹å¦‚ "paragraph", "list")
- [x] æ–°å¢ `sub_index` æ¬„ä½ (å­åˆ†å¡Šç´¢å¼•ï¼Œ0 è¡¨ç¤ºç„¡å­åˆ†å¡Š)
- [x] æ–°å¢ `total_sub_chunks` æ¬„ä½ (å­åˆ†å¡Šç¸½æ•¸)
- [x] æ–°å¢ `vectorization_strategy` æ¬„ä½ ("hybrid" | "raw_only" | "sub_chunked")
- [x] æ–°å¢ `chunk_summary` æ¬„ä½ (å€å¡Šæ‘˜è¦)
- [x] æ–°å¢ `logical_chunk_id` æ¬„ä½ (AI è¿”å›çš„åŸå§‹ chunk_id)
- [x] ä¿®æ”¹ `vector_db_service.py` çš„ `insert_vectors()`

#### 3.2.5 å„²å­˜ä¸€è‡´æ€§ âœ…
- [x] ç¢ºä¿æ‰€æœ‰ chunks ä½¿ç”¨åŒä¸€ `document_id`
- [x] æ”¯æ´æŒ‰ `document_id` æ‰¹é‡åˆªé™¤èˆŠå‘é‡ (å·²æœ‰åŠŸèƒ½)
- [x] è™•ç†å­åˆ†å¡Šçš„ unique ID ç”Ÿæˆ (`{doc_id}_chunk_{chunk_id}_sub_{sub_index}`)

### 3.3 å¯¦ç¾ç´°ç¯€

#### æ ¸å¿ƒå‡½æ•¸ï¼šæ™ºèƒ½å‘é‡åŒ–

```python
def process_logical_chunk_for_vectorization(
    chunk: LogicalChunk,
    raw_text: str,
    document_id: str,
    user_id: str
) -> List[VectorData]:
    """
    è™•ç†å–®å€‹ logical chunk çš„å‘é‡åŒ–
    ç¢ºä¿æ‰€æœ‰å…§å®¹éƒ½è¢«å‘é‡åŒ–ï¼Œä¸ä¸Ÿå¤±ä»»ä½•è³‡è¨Š
    """
    HYBRID_THRESHOLD = 350
    SAFE_LENGTH = 480
    SUB_CHUNK_OVERLAP = 50

    vectors = []

    if len(raw_text) <= HYBRID_THRESHOLD:
        # === çŸ­ chunkï¼šä½¿ç”¨æ··åˆå¢å¼· ===
        payload = f"[Summary]: {chunk.summary}\n[Content]: {raw_text}"
        vectors.append(create_vector_data(
            content=payload,
            chunk=chunk,
            strategy="hybrid",
            sub_index=0,
            total_sub_chunks=1
        ))

    elif len(raw_text) <= SAFE_LENGTH:
        # === ä¸­ç­‰ chunkï¼šåªç”¨åŸæ–‡ï¼ˆå®Œæ•´ï¼‰ ===
        vectors.append(create_vector_data(
            content=raw_text,
            chunk=chunk,
            strategy="raw_only",
            sub_index=0,
            total_sub_chunks=1
        ))

    else:
        # === é•· chunkï¼šå­åˆ†å¡Š ===
        sub_chunks = smart_split_text(raw_text, SAFE_LENGTH, SUB_CHUNK_OVERLAP)
        for i, sub_text in enumerate(sub_chunks):
            vectors.append(create_vector_data(
                content=sub_text,
                chunk=chunk,
                strategy="sub_chunked",
                sub_index=i,
                total_sub_chunks=len(sub_chunks)
            ))

    return vectors
```

#### æ ¸å¿ƒå‡½æ•¸ï¼šåŸæ–‡æå–

```python
def extract_text_by_line_ids(
    start_id: str,      # "L001"
    end_id: str,        # "L010"
    line_mapping: Dict[str, Dict],
    full_text: str
) -> str:
    """
    æ ¹æ“šè¡Œè™Ÿç¯„åœå¾åŸæ–‡ä¸­æå–æ–‡æœ¬
    """
    start_info = line_mapping.get(start_id)
    end_info = line_mapping.get(end_id)

    if not start_info or not end_info:
        raise ValueError(f"Invalid line IDs: {start_id} - {end_id}")

    start_pos = start_info["start"]
    end_pos = end_info["end"]

    return full_text[start_pos:end_pos]
```

### 3.4 å‘é‡å±¤æ¬¡çµæ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Two-Stage Hybrid Search                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Level 1: Document Summary Vector (æ–‡æª”ç´š) - ä¿æŒä¸è®Š       â”‚
â”‚  â”œâ”€â”€ å…§å®¹: filename + content_summary + keywords + domains  â”‚
â”‚  â”œâ”€â”€ RRF æ¬Šé‡: 2.0                                          â”‚
â”‚  â””â”€â”€ ç”¨é€”: Stage 1 ç²—ç¯©é¸                                   â”‚
â”‚                                                             â”‚
â”‚  Level 2: Logical Chunk Vectors (å€å¡Šç´š) - æ–°çš„             â”‚
â”‚  â”œâ”€â”€ å…§å®¹: æ ¹æ“šé•·åº¦é¸æ“‡ç­–ç•¥ (æ··åˆ/åŸæ–‡/å­åˆ†å¡Š)              â”‚
â”‚  â”œâ”€â”€ RRF æ¬Šé‡: 1.0                                          â”‚
â”‚  â”œâ”€â”€ ç”¨é€”: Stage 2 ç²¾æ’åº                                   â”‚
â”‚  â””â”€â”€ Metadata: document_id, chunk_id, chunk_type,           â”‚
â”‚                start_line, end_line, sub_index              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å·²ä¿®æ”¹æª”æ¡ˆ**:
- `app/core/config.py` - æ–°å¢æ™ºèƒ½å­åˆ†å¡Šé…ç½®åƒæ•¸
- `app/services/document/line_marker_service.py` - æ–°å¢ `smart_split_text()`, `ChunkVectorizationResult`, `process_logical_chunk_for_vectorization()`
- `app/services/document/semantic_summary_service.py` - æ–°å¢ `_create_chunk_vectors_from_logical_chunks()`, ä¿®æ”¹ä¸»æµç¨‹æ”¯æ´ AI é‚è¼¯åˆ†å¡Š
- `app/services/vector/vector_db_service.py` - æ“´å±• metadata è™•ç†æ”¯æ´ Phase 3 æ–°æ¬„ä½

---

## Phase 4: æœç´¢èª¿æ•´ âœ… å·²å®Œæˆ

### 4.1 æœç´¢çµæœæ¨¡å‹æ“´å±•
- [x] `SemanticSearchResult` æ–°å¢ `start_line`
- [x] `SemanticSearchResult` æ–°å¢ `end_line`
- [x] `SemanticSearchResult` æ–°å¢ `chunk_type`

### 4.2 æœç´¢æœå‹™æ›´æ–°
- [x] æœç´¢çµæœå¡«å……è¡Œè™Ÿè³‡è¨Š
- [x] ç¢ºä¿ Two-Stage Hybrid Search å…¼å®¹
- [x] RRF Fusion å‚³éè¡Œè™Ÿè³‡è¨Š

### 4.3 API éŸ¿æ‡‰æ›´æ–°
- [x] `semantic_search()` è¿”å›è¡Œè™Ÿè³‡è¨Š (è‡ªå‹•é€éæ¨¡å‹è®Šæ›´ç”Ÿæ•ˆ)

**å·²ä¿®æ”¹æª”æ¡ˆ**:
- `app/models/vector_models.py` - SemanticSearchResult æ–°å¢ start_line, end_line, chunk_type æ¬„ä½
- `app/services/vector/vector_db_service.py` - search_similar_vectors() å¡«å……è¡Œè™Ÿè³‡è¨Šå’Œå®Œæ•´ metadata
- `app/services/vector/enhanced_search_service.py` - RRF èåˆçµæœå‚³éè¡Œè™Ÿè³‡è¨Š

---

## Phase 5: æ•´åˆæ¸¬è©¦

### 5.1 å–®å…ƒæ¸¬è©¦
- [ ] è¡Œè™Ÿæ¨™è¨˜å‡½æ•¸æ¸¬è©¦
- [ ] åˆ†æ‰¹è™•ç†é‚è¼¯æ¸¬è©¦
- [ ] AI åˆ†å¡Šè¼¸å‡ºæ ¼å¼é©—è­‰
- [ ] åŸæ–‡æå–æ­£ç¢ºæ€§æ¸¬è©¦

### 5.2 ç«¯åˆ°ç«¯æ¸¬è©¦
- [ ] åœ–ç‰‡æ–‡æª” (ç™¼ç¥¨ã€æ”¶æ“š)
- [ ] çŸ­ PDF (< 10 é )
- [ ] é•· PDF (> 10 é ï¼Œè§¸ç™¼åˆ†æ‰¹)
- [ ] ç´”æ–‡å­—æ–‡æª”
- [ ] Word æ–‡æª”

### 5.3 æª¢ç´¢é©—è­‰
- [ ] æœç´¢çµæœåŒ…å«æ­£ç¢ºè¡Œè™Ÿ
- [ ] è¡Œè™Ÿå°æ‡‰åŸæ–‡ä½ç½®æ­£ç¢º
- [ ] ç²¾ç¢ºå¼•ç”¨åŠŸèƒ½æ­£å¸¸

---

## é€²åº¦ç¸½è¦½

| Phase | æè¿° | ç‹€æ…‹ | å®Œæˆæ—¥æœŸ |
|-------|------|------|----------|
| Phase 0 | æ¬„ä½æ¸…ç† | âœ… å®Œæˆ | 2025-11-24 |
| Phase 1 | å‰è™•ç†æ”¹é€  | âœ… å®Œæˆ | 2025-11-25 |
| Phase 2 | Prompt ä¿®æ”¹ | âœ… å®Œæˆ | 2025-11-25 |
| Phase 3 | å‘é‡åŒ–é‡æ§‹ | âœ… å®Œæˆ | 2025-11-25 |
| Phase 4 | æœç´¢èª¿æ•´ | âœ… å®Œæˆ | 2025-11-25 |
| Phase 5 | æ•´åˆæ¸¬è©¦ | ğŸ”² å¾…é–‹å§‹ | - |

---

## é—œéµæ±ºç­–è¨˜éŒ„

| æ—¥æœŸ | æ±ºç­–é … | é¸æ“‡ |
|------|--------|------|
| 2025-11-25 | AI è¼¸å‡ºæ ¼å¼ | åªè¿”å›è¡Œè™Ÿåº§æ¨™ï¼Œä¸è¿”å›åŸæ–‡ |
| 2025-11-25 | æ‰¹æ¬¡å¤§å° | æ··åˆç­–ç•¥ (PDF 5é /æ‰¹, æ–‡å­— 10K/æ‰¹) |
| 2025-11-25 | Fallback | é‡è©¦ä¸€æ¬¡å¾Œå ±éŒ¯ï¼Œä¸é™ç´šåˆ°å›ºå®šåˆ†å¡Š |
| 2025-11-25 | è¡Œè™Ÿè¿”å› | æœç´¢çµæœåŒ…å« start_line, end_line |
| 2025-11-25 | è¡Œè™Ÿæ¨™è¨˜ç§»é™¤ | å‘é‡åŒ–å’Œæœç´¢çµæœçš„ chunk_text è‡ªå‹•ç§»é™¤è¡Œè™Ÿæ¨™è¨˜ |
| 2025-11-25 | åœ–ç‰‡æ–‡æª”çµ±ä¸€è™•ç† | åœ–ç‰‡ OCR çµæœå„²å­˜ç´”æ–‡æœ¬ï¼Œèˆ‡æ–‡å­—æ–‡æª”è™•ç†æµç¨‹ä¸€è‡´ |
| 2025-11-25 | çŸ­ chunks åˆä½µ | ä¸åšå¾Œè™•ç†åˆä½µï¼Œå®Œå…¨ä¿¡ä»» AI èªç¾©åˆ†çµ„ |
| 2025-11-25 | å‘é‡åŒ–ç­–ç•¥ | æ™ºèƒ½å­åˆ†å¡Š (â‰¤350 æ··åˆå¢å¼·, 351-480 åŸæ–‡, >480 å­åˆ†å¡Š) |
| 2025-11-25 | å‘é‡åŒ–æ¨¡å‹ | `paraphrase-multilingual-mpnet-base-v2`, 512 å­—ç¬¦é™åˆ¶, 768 ç¶­ |
| 2025-11-25 | æ··åˆå¢å¼·æ ¼å¼ | `[Summary]: {summary}\n[Content]: {raw_text}` |
| 2025-11-25 | Phase 3 å¯¦ç¾ | æ™ºèƒ½å‘é‡åŒ–å‡½æ•¸æ”¾åœ¨ `line_marker_service.py` é¿å…å¾ªç’°ä¾è³´ |
| 2025-11-25 | Phase 4 æœç´¢èª¿æ•´ | æ¨¡å‹æ“´å±• + metadata é€å‚³ï¼Œä¸ä¿®æ”¹æœç´¢ç®—æ³• |

---

## å‚™è¨»

1. **ä¿ç•™ Summary Vector**: Document Summary Vector æ˜¯ Stage 1 æ•ˆç‡é—œéµ
2. **RRF ç¶­æŒç¾ç‹€**: æ¬Šé‡å’Œå…¬å¼ç„¡éœ€ä¿®æ”¹
3. **æ¼¸é€²å¼é·ç§»**: å…ˆåœ¨æ–°æ–‡æª”æ¸¬è©¦ï¼Œé©—è­‰å¾Œè™•ç†èˆŠæ•¸æ“š
4. **æ™ºèƒ½å­åˆ†å¡Š**: ç¢ºä¿æ‰€æœ‰å…§å®¹éƒ½è¢«å‘é‡åŒ–ï¼Œä¸ä¸Ÿå¤±ä»»ä½•è³‡è¨Š
5. **å‘é‡åŒ–é–¾å€¼**: 350 å­—ç¬¦ (æ··åˆå¢å¼·) / 480 å­—ç¬¦ (å–®å‘é‡) / 50 å­—ç¬¦ (é‡ç–Š)
