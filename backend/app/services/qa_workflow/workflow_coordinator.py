"""
å·¥ä½œæµå”èª¿å™¨

è™•ç†å·¥ä½œæµåœ¨å„å€‹éšæ®µçš„éˆæ´»è½‰æ›,ç¢ºä¿å°è©±æµæš¢
æ”¯æŒ: æ¾„æ¸…â†’æœç´¢/ç›´æ¥å›ç­”ã€æœç´¢â†’æ¾„æ¸…ã€æ‰¹å‡†æ©Ÿåˆ¶ç­‰
"""
import logging
from typing import Optional
from motor.motor_asyncio import AsyncIOMotorDatabase

from app.core.logging_utils import AppLogger, log_event, LogLevel
from app.models.vector_models import AIQARequest, AIQAResponse
from app.models.question_models import QuestionClassification, QuestionIntent

logger = AppLogger(__name__, level=logging.DEBUG).get_logger()


class WorkflowCoordinator:
    """å·¥ä½œæµå”èª¿å™¨ - ç®¡ç†å„éšæ®µé–“çš„è½‰æ›"""
    
    async def handle_clarification_response(
        self,
        original_request: AIQARequest,
        clarification_response: str,
        db: AsyncIOMotorDatabase,
        user_id: Optional[str] = None,
        request_id: Optional[str] = None
    ) -> AIQAResponse:
        """
        è™•ç†ç”¨æˆ¶çš„æ¾„æ¸…å›ç­”,é‡æ–°åˆ†é¡ä¸¦è·¯ç”±
        
        Args:
            original_request: åŸå§‹è«‹æ±‚
            clarification_response: ç”¨æˆ¶çš„æ¾„æ¸…å›ç­”
            db: æ•¸æ“šåº«é€£æ¥
            user_id: ç”¨æˆ¶ID
            request_id: è«‹æ±‚ID
            
        Returns:
            AIQAResponse: è™•ç†çµæœ
        """
        logger.info(f"è™•ç†æ¾„æ¸…å›ç­”: {clarification_response[:100]}")
        
        # å‰µå»ºæ–°è«‹æ±‚,åŒ…å«æ¾„æ¸…å›ç­”
        new_request = AIQARequest(
            question=clarification_response,
            conversation_id=original_request.conversation_id,
            session_id=original_request.session_id,
            model_preference=original_request.model_preference,
            context_limit=original_request.context_limit,
            # ç¹¼æ‰¿å…¶ä»–è¨­ç½®
            **{k: v for k, v in original_request.model_dump().items() 
               if k not in ['question']}
        )
        
        # é‡æ–°é€²å…¥æ™ºèƒ½è·¯ç”±æµç¨‹(é€™æ¬¡æœƒå¸¶ä¸Šæ¾„æ¸…çš„å°è©±æ­·å²)
        from app.services.qa_orchestrator import qa_orchestrator
        
        logger.info("æ¾„æ¸…å¾Œé‡æ–°è·¯ç”±,AIå°‡çœ‹åˆ°å®Œæ•´å°è©±ä¸Šä¸‹æ–‡")
        response = await qa_orchestrator.process_qa_request_intelligent(
            db=db,
            request=new_request,
            user_id=user_id,
            request_id=request_id
        )
        
        # åœ¨ workflow_state ä¸­æ¨™è¨˜é€™æ˜¯æ¾„æ¸…å¾Œçš„è™•ç†
        if response.workflow_state:
            response.workflow_state["previous_step"] = "clarification"
            response.workflow_state["clarification_resolved"] = True
        
        return response
    
    async def handle_search_no_results(
        self,
        original_request: AIQARequest,
        classification: QuestionClassification,
        db: AsyncIOMotorDatabase,
        user_id: Optional[str] = None,
        request_id: Optional[str] = None
    ) -> AIQAResponse:
        """
        è™•ç†æœç´¢ç„¡çµæœçš„æƒ…æ³,æä¾›é¸é …:
        1. èª¿æ•´æœç´¢æ¢ä»¶(ç”Ÿæˆæ¾„æ¸…å•é¡Œ)
        2. ä½¿ç”¨é€šç”¨çŸ¥è­˜å›ç­”
        
        Args:
            original_request: åŸå§‹è«‹æ±‚
            classification: åˆ†é¡çµæœ
            db: æ•¸æ“šåº«é€£æ¥
            user_id: ç”¨æˆ¶ID
            request_id: è«‹æ±‚ID
            
        Returns:
            AIQAResponse: è™•ç†çµæœ
        """
        logger.info(f"æœç´¢ç„¡çµæœ,ç”Ÿæˆå»ºè­°")
        
        # ç”Ÿæˆæ™ºèƒ½å»ºè­°(å¸¶å°è©±æ­·å²)
        from app.services.qa_workflow.question_classifier_service import question_classifier_service
        
        clarification_data = await question_classifier_service.generate_clarification_question(
            original_question=original_request.question,
            ambiguity_reason="æœªåœ¨æ–‡æª”åº«ä¸­æ‰¾åˆ°ç›¸é—œå…§å®¹",
            db=db,
            user_id=user_id,
            conversation_id=original_request.conversation_id  # å‚³éå°è©±ID
        )
        
        clarification_question = clarification_data.get(
            "clarification_question",
            "æœªæ‰¾åˆ°ç›¸é—œæ–‡æª”ã€‚æ‚¨å¯ä»¥:\n1. èª¿æ•´æœç´¢é—œéµè©\n2. ä¸Šå‚³ç›¸é—œæ–‡æª”\n3. è®“æˆ‘åŸºæ–¼é€šç”¨çŸ¥è­˜å›ç­”"
        )
        
        suggested_responses = clarification_data.get(
            "suggested_responses",
            ["ä½¿ç”¨ä¸åŒçš„é—œéµè©é‡æ–°æå•", "ä¸Šå‚³ç›¸é—œæ–‡æª”", "ç”¨é€šç”¨çŸ¥è­˜å›ç­”"]
        )
        
        # æ§‹å»ºå›ç­”
        answer = f"ğŸ” {clarification_question}\n\n"
        answer += "ğŸ’¡ å»ºè­°çš„é¸é …:\n"
        for i, option in enumerate(suggested_responses, 1):
            answer += f"{i}. {option}\n"
        
        # ä¿å­˜å°è©±
        from app.services.qa_workflow.conversation_helper import conversation_helper
        await conversation_helper.save_qa_to_conversation(
            db=db,
            conversation_id=original_request.conversation_id,
            user_id=str(user_id) if user_id else None,
            question=original_request.question,
            answer=answer,
            tokens_used=100,
            source_documents=[]
        )
        
        from app.models.vector_models import QueryRewriteResult
        
        return AIQAResponse(
            answer=answer,
            source_documents=[],
            confidence_score=0.0,
            tokens_used=100,
            processing_time=0.5,
            query_rewrite_result=QueryRewriteResult(
                original_query=original_request.question,
                rewritten_queries=[original_request.question],
                extracted_parameters={},
                intent_analysis="æœç´¢ç„¡çµæœ,æä¾›èª¿æ•´å»ºè­°"
            ),
            semantic_search_contexts=[],
            session_id=original_request.session_id,
            classification=classification,
            workflow_state={
                "current_step": "need_clarification",
                "strategy_used": "search_no_results_clarification",
                "api_calls": 2,
                "clarification_question": clarification_question,
                "suggested_responses": suggested_responses,
                "pending_action": "provide_clarification"
            },
            next_action="provide_clarification",
            pending_approval="clarification"
        )
    
    def should_request_search_approval(
        self,
        classification: QuestionClassification,
        config: dict
    ) -> bool:
        """
        åˆ¤æ–·æ˜¯å¦éœ€è¦è«‹æ±‚æœç´¢æ‰¹å‡†
        
        Args:
            classification: å•é¡Œåˆ†é¡çµæœ
            config: ç³»çµ±é…ç½®
            
        Returns:
            bool: æ˜¯å¦éœ€è¦æ‰¹å‡†
        """
        # å¦‚æœç¦ç”¨æ‰¹å‡†æ©Ÿåˆ¶,ç›´æ¥è¿”å› False
        if config.get('auto_approve_all_searches', False):
            return False
        
        # ç°¡å–®æŸ¥è©¢å’Œå¯’æš„ä¸éœ€è¦æ‰¹å‡†
        if classification.intent in [
            QuestionIntent.GREETING,
            QuestionIntent.CHITCHAT,
            QuestionIntent.SIMPLE_FACTUAL
        ]:
            return False
        
        # è¤‡é›œåˆ†æå’Œæ–‡æª”æœç´¢éœ€è¦æ‰¹å‡†
        if classification.intent in [
            QuestionIntent.DOCUMENT_SEARCH,
            QuestionIntent.COMPLEX_ANALYSIS
        ]:
            # å¦‚æœç½®ä¿¡åº¦å¾ˆé«˜ä¸”é…ç½®å…è¨±è‡ªå‹•æ‰¹å‡†,å‰‡è·³é
            if classification.confidence > 0.9 and config.get('auto_approve_high_confidence', False):
                logger.info(f"é«˜ç½®ä¿¡åº¦({classification.confidence:.2f}),è‡ªå‹•æ‰¹å‡†æœç´¢")
                return False
            
            return True
        
        return False


# å‰µå»ºå…¨å±€å¯¦ä¾‹
workflow_coordinator = WorkflowCoordinator()

