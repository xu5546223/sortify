"""
å•é¡Œåˆ†é¡å™¨æœå‹™

ä½¿ç”¨ Gemini 2.0 Flash å¿«é€Ÿåˆ†é¡ç”¨æˆ¶å•é¡Œçš„æ„åœ–é¡å‹
"""
import logging
import time
from typing import Optional
from motor.motor_asyncio import AsyncIOMotorDatabase

from app.core.logging_utils import AppLogger, log_event, LogLevel
from app.models.question_models import (
    QuestionIntent,
    QuestionClassification,
    QuestionClassifierConfig
)
from app.services.ai.unified_ai_service_simplified import (
    unified_ai_service_simplified,
    AIRequest,
    TaskType
)

logger = AppLogger(__name__, level=logging.DEBUG).get_logger()


class QuestionClassifierService:
    """å•é¡Œåˆ†é¡å™¨æœå‹™"""
    
    def __init__(self):
        # å¾é…ç½®æ–‡ä»¶è®€å–è¨­å®š(ä¸ç¡¬ç·¨ç¢¼)
        from app.core.config import settings
        
        self.config = QuestionClassifierConfig(
            enabled=settings.QUESTION_CLASSIFIER_ENABLED,
            model=settings.QUESTION_CLASSIFIER_MODEL,
            confidence_threshold=settings.QUESTION_CLASSIFIER_CONFIDENCE_THRESHOLD
        )
        logger.info(f"å•é¡Œåˆ†é¡å™¨åˆå§‹åŒ–å®Œæˆ,ä½¿ç”¨æ¨¡å‹: {self.config.model}, å•Ÿç”¨ç‹€æ…‹: {self.config.enabled}")
    
    async def classify_question(
        self,
        question: str,
        conversation_history: Optional[list] = None,
        has_cached_documents: bool = False,
        cached_documents_info: Optional[list] = None,
        db: Optional[AsyncIOMotorDatabase] = None,
        user_id: Optional[str] = None
    ) -> QuestionClassification:
        """
        åˆ†é¡ç”¨æˆ¶å•é¡Œçš„æ„åœ–
        
        Args:
            question: ç”¨æˆ¶å•é¡Œ
            conversation_history: å°è©±æ­·å²(å¯é¸)
            has_cached_documents: æ˜¯å¦æœ‰ç·©å­˜çš„æ–‡æª”
            db: æ•¸æ“šåº«é€£æ¥
            user_id: ç”¨æˆ¶ID(ç”¨æ–¼æ—¥èªŒè¨˜éŒ„)
            
        Returns:
            QuestionClassification: åˆ†é¡çµæœ
        """
        if not self.config.enabled:
            logger.warning("å•é¡Œåˆ†é¡å™¨å·²ç¦ç”¨,è¿”å›é»˜èªåˆ†é¡")
            return self._get_default_classification(question)
        
        start_time = time.time()
        
        try:
            # æº–å‚™ä¸Šä¸‹æ–‡ä¿¡æ¯
            has_conversation_history = bool(conversation_history and len(conversation_history) > 0)
            
            # æ ¼å¼åŒ–å°è©±æ­·å²
            conversation_history_text = ""
            if has_conversation_history:
                conversation_history_text = "=== æœ€è¿‘å°è©±è¨˜éŒ„ ===\n"
                
                # é‡è¦ï¼šæˆå°è™•ç†ç”¨æˆ¶å•é¡Œå’ŒAIå›ç­”ï¼Œä¿æŒä¸Šä¸‹æ–‡é€£è²«æ€§
                i = 0
                while i < len(conversation_history):
                    msg = conversation_history[i]
                    role_name = "ç”¨æˆ¶" if msg.get("role") == "user" else "åŠ©æ‰‹"
                    content = msg.get("content", "")
                    
                    # æ™ºèƒ½æˆªæ–·ï¼šç”¨æˆ¶å•é¡Œä¿ç•™å®Œæ•´ï¼ŒAIå›ç­”ä¿ç•™é—œéµéƒ¨åˆ†
                    if role_name == "ç”¨æˆ¶":
                        # ç”¨æˆ¶å•é¡Œä¿ç•™å®Œæ•´ï¼ˆæœ€å¤š300å­—ï¼Œç¢ºä¿ä¸ä¸Ÿå¤±é—œéµä¿¡æ¯ï¼‰
                        if len(content) > 300:
                            content = content[:300] + "..."
                        conversation_history_text += f"ç”¨æˆ¶: {content}\n"
                    else:
                        # AIå›ç­”è™•ç†ç­–ç•¥ï¼šç›¡é‡ä¿ç•™å®Œæ•´å…§å®¹
                        if "æ¾„æ¸…" in content or "ğŸ”–" in content or "ğŸ’¡" in content:
                            # é€™æ˜¯æ¾„æ¸…å›ç­”ï¼Œæå–æ ¸å¿ƒæ¾„æ¸…å•é¡Œéƒ¨åˆ†å³å¯ï¼ˆæ¾„æ¸…å›ç­”é€šå¸¸å¾ˆé•·ä½†é‡é»åœ¨å•é¡Œï¼‰
                            lines = content.split('\n')
                            # ä¿ç•™"é—œæ–¼æ‚¨çš„å•é¡Œ"å’Œ"ğŸ’¡"é–‹é ­çš„æ¾„æ¸…å•é¡Œ
                            core_parts = []
                            for line in lines:
                                if 'é—œæ–¼æ‚¨çš„å•é¡Œ' in line or 'ğŸ’¡' in line:
                                    core_parts.append(line)
                                    if len(core_parts) >= 2:
                                        break
                            if core_parts:
                                content = '\n'.join(core_parts)
                            elif len(content) > 600:
                                content = content[:600] + "..."
                        else:
                            # æ™®é€šå›ç­”ï¼šæ„åœ–åˆ†é¡æ™‚é©åº¦ä¿ç•™å³å¯ï¼ˆç†è§£ä¸Šä¸‹æ–‡å³å¯ï¼‰
                            # ä¿ç•™å‰800å­—ï¼ˆåŒ…å«æ‘˜è¦å’Œä¸»è¦ä¿¡æ¯ï¼‰
                            if len(content) > 800:
                                content = content[:800] + "...[å¾ŒçºŒçœç•¥]"
                        
                        conversation_history_text += f"åŠ©æ‰‹: {content}\n"
                    
                    i += 1
                
                conversation_history_text += "=== ç•¶å‰å•é¡Œ ==="
            else:
                conversation_history_text = "ç„¡å°è©±æ­·å²"
            
            # æ ¼å¼åŒ–æ–‡æª”æ± ä¿¡æ¯ï¼ˆæŒ‰ç›¸é—œæ€§æ’åºï¼‰
            cached_documents_text = ""
            if cached_documents_info and len(cached_documents_info) > 0:
                cached_documents_text = "=== æ–‡æª”æ± ï¼ˆæœƒè©±æ–‡æª”ï¼ŒæŒ‰ç›¸é—œæ€§æ’åºï¼‰===\n"
                for doc_info in cached_documents_info:
                    doc_id = doc_info.get("document_id", "unknown")
                    filename = doc_info.get("filename", "æœªçŸ¥æ–‡ä»¶")
                    summary = doc_info.get("summary", "")
                    relevance_score = doc_info.get("relevance_score", 0.0)
                    access_count = doc_info.get("access_count", 0)
                    key_concepts = doc_info.get("key_concepts", [])
                    semantic_tags = doc_info.get("semantic_tags", [])
                    ref_num = doc_info.get("reference_number", 0)
                    
                    cached_documents_text += f"æ–‡æª”{ref_num} (ID: {doc_id}):\n"
                    cached_documents_text += f"  æ–‡ä»¶å: {filename}\n"
                    cached_documents_text += f"  ç›¸é—œæ€§: {relevance_score:.2f} (è¨ªå• {access_count} æ¬¡)\n"
                    if summary:
                        cached_documents_text += f"  æ‘˜è¦: {summary[:200]}{'...' if len(summary) > 200 else ''}\n"
                    if key_concepts:
                        cached_documents_text += f"  é—œéµæ¦‚å¿µ: {', '.join(key_concepts)}\n"
                    if semantic_tags:
                        cached_documents_text += f"  èªç¾©æ¨™ç±¤: {', '.join(semantic_tags)}\n"
                    cached_documents_text += "\n"
            else:
                cached_documents_text = "ç„¡ç·©å­˜æ–‡æª”"
            
            # ğŸ” èª¿è©¦è¼¸å‡ºï¼šé¡¯ç¤ºå‚³éçµ¦AIçš„å®Œæ•´å…§å®¹
            logger.info("="*80)
            logger.info("ğŸ“¤ å‚³éçµ¦AIæ„åœ–åˆ†é¡çš„å…§å®¹:")
            logger.info(f"ç•¶å‰å•é¡Œ: {question}")
            logger.info(f"å°è©±æ­·å²:\n{conversation_history_text}")
            logger.info(f"ç·©å­˜æ–‡æª”:\n{cached_documents_text}")
            logger.info("="*80)
            
            # èª¿ç”¨ AI é€²è¡Œåˆ†é¡
            ai_request = AIRequest(
                task_type=TaskType.QUESTION_INTENT_CLASSIFICATION,
                content=question,
                model_preference=self.config.model,
                prompt_params={
                    "user_question": question,
                    "conversation_history": conversation_history_text,
                    "has_conversation_history": str(has_conversation_history),
                    "has_cached_documents": str(has_cached_documents),
                    "cached_documents_info": cached_documents_text
                },
                user_id=user_id,
                generation_params_override={
                    "temperature": self.config.temperature,
                    "max_output_tokens": self.config.max_output_tokens
                }
            )
            
            response = await unified_ai_service_simplified.process_request(ai_request, db)
            
            if not response.success:
                logger.error(f"å•é¡Œåˆ†é¡å¤±æ•—: {response.error_message}")
                return self._get_fallback_classification(question, "AI åˆ†é¡å¤±æ•—")
            
            # è§£æåˆ†é¡çµæœ
            classification_data = response.output_data
            
            # ğŸ” èª¿è©¦è¼¸å‡ºï¼šé¡¯ç¤ºAIçš„åˆ†é¡çµæœ
            logger.info("="*80)
            logger.info("ğŸ“¥ AIåˆ†é¡çµæœ:")
            logger.info(f"æ„åœ–: {classification_data.get('intent')}")
            logger.info(f"ç½®ä¿¡åº¦: {classification_data.get('confidence')}")
            logger.info(f"æ¨ç†: {classification_data.get('reasoning')}")
            logger.info("="*80)
            
            # é©—è­‰ä¸¦æ§‹å»ºåˆ†é¡çµæœ
            classification = QuestionClassification(
                intent=QuestionIntent(classification_data.get("intent", "document_search")),
                confidence=float(classification_data.get("confidence", 0.5)),
                reasoning=classification_data.get("reasoning", ""),
                requires_documents=bool(classification_data.get("requires_documents", True)),
                requires_context=bool(classification_data.get("requires_context", False)),
                suggested_strategy=classification_data.get("suggested_strategy", "standard_search"),
                query_complexity=classification_data.get("query_complexity", "moderate"),
                estimated_api_calls=int(classification_data.get("estimated_api_calls", 3)),
                clarification_question=classification_data.get("clarification_question"),
                suggested_responses=classification_data.get("suggested_responses"),
                target_document_ids=classification_data.get("target_document_ids"),
                target_document_reasoning=classification_data.get("target_document_reasoning")
            )
            
            processing_time = time.time() - start_time
            
            logger.info(
                f"å•é¡Œåˆ†é¡å®Œæˆ: intent={classification.intent}, "
                f"confidence={classification.confidence:.2f}, "
                f"time={processing_time:.2f}s"
            )
            
            # è¨˜éŒ„æ—¥èªŒ
            if db is not None:
                await log_event(
                    db=db,
                    level=LogLevel.INFO,
                    message=f"å•é¡Œåˆ†é¡: {classification.intent}",
                    source="service.question_classifier.classify",
                    user_id=user_id,
                    details={
                        "question": question[:100],
                        "intent": classification.intent,
                        "confidence": classification.confidence,
                        "strategy": classification.suggested_strategy,
                        "processing_time": processing_time,
                        "api_calls_estimate": classification.estimated_api_calls
                    }
                )
            
            # ç½®ä¿¡åº¦æª¢æŸ¥ - ç¢ºä¿æ¨¡ç³Šå•é¡Œè¢«è­˜åˆ¥
            # æ­£ç¢ºé‚è¼¯: æœ‰å°è©±æ­·å²æ™‚ï¼ŒAIæ‡‰è©²æ›´ç¢ºå®šï¼Œå› æ­¤è¦æ±‚æ›´é«˜çš„ç½®ä¿¡åº¦
            effective_threshold = self.config.confidence_threshold  # é»˜èª 0.8
            
            # å¦‚æœæœ‰å°è©±æ­·å²ï¼Œå¯¦éš›ä¸Šæ‡‰è©²**æé«˜**ç½®ä¿¡åº¦è¦æ±‚
            # å› ç‚ºæœ‰æ›´å¤šä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒAIæ‡‰è©²èƒ½çµ¦å‡ºæ›´ç¢ºå®šçš„åˆ¤æ–·
            # ä½†ç‚ºäº†å¹³æ»‘éæ¸¡ï¼Œæš«æ™‚ä¿æŒç›¸åŒæ¨™æº–
            if conversation_history and len(conversation_history) > 0:
                # ä¿æŒç›¸åŒæ¨™æº–ï¼Œä¸é™ä½ä¹Ÿä¸æé«˜
                logger.info(f"æœ‰å°è©±æ­·å²ï¼Œç¶­æŒç½®ä¿¡åº¦é–¾å€¼: {effective_threshold:.2f}")
            
            if classification.confidence < effective_threshold:
                logger.warning(
                    f"åˆ†é¡ç½®ä¿¡åº¦ä½æ–¼é–¾å€¼ ({classification.confidence:.2f} < {effective_threshold:.2f}), "
                    f"éœ€è¦æ¾„æ¸…"
                )
                # å¦‚æœç½®ä¿¡åº¦ä½,æ”¹ç‚º clarification_needed
                if classification.intent not in [QuestionIntent.GREETING, QuestionIntent.CHITCHAT]:
                    classification.intent = QuestionIntent.CLARIFICATION_NEEDED
                    classification.suggested_strategy = "ask_clarification"
                    logger.info(f"ç½®ä¿¡åº¦ä¸è¶³,æ”¹ç‚ºéœ€è¦æ¾„æ¸…")
            else:
                logger.info(f"ç½®ä¿¡åº¦{classification.confidence:.2f}è¶³å¤ ,ä¿æŒæ„åœ–{classification.intent}")
            
            return classification
            
        except Exception as e:
            logger.error(f"å•é¡Œåˆ†é¡ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            if db is not None:
                await log_event(
                    db=db,
                    level=LogLevel.ERROR,
                    message=f"å•é¡Œåˆ†é¡éŒ¯èª¤: {str(e)}",
                    source="service.question_classifier.classify_error",
                    user_id=user_id,
                    details={"question": question[:100], "error": str(e)}
                )
            return self._get_fallback_classification(question, f"åˆ†é¡éŒ¯èª¤: {str(e)}")
    
    def _get_default_classification(self, question: str) -> QuestionClassification:
        """ç²å–é»˜èªåˆ†é¡(ç•¶åˆ†é¡å™¨ç¦ç”¨æ™‚)"""
        return QuestionClassification(
            intent=QuestionIntent.DOCUMENT_SEARCH,
            confidence=0.5,
            reasoning="åˆ†é¡å™¨å·²ç¦ç”¨,ä½¿ç”¨é»˜èªç­–ç•¥",
            requires_documents=True,
            requires_context=False,
            suggested_strategy="standard_search",
            query_complexity="moderate",
            estimated_api_calls=3
        )
    
    def _get_fallback_classification(self, question: str, reason: str) -> QuestionClassification:
        """ç²å–å›é€€åˆ†é¡(ç•¶åˆ†é¡å¤±æ•—æ™‚)"""
        # ä½¿ç”¨ç°¡å–®çš„è¦å‰‡åˆ¤æ–·
        q_lower = question.lower().strip()
        q_len = len(question)
        
        # å¯’æš„åˆ¤æ–·
        greetings = ["ä½ å¥½", "hi", "hello", "å—¨", "å“ˆå›‰", "æ—©å®‰", "åˆå®‰", "æ™šå®‰"]
        if any(g in q_lower for g in greetings) and q_len < 10:
            return QuestionClassification(
                intent=QuestionIntent.GREETING,
                confidence=0.8,
                reasoning=f"è¦å‰‡åˆ¤æ–·: å¯’æš„å•å€™ ({reason})",
                requires_documents=False,
                requires_context=False,
                suggested_strategy="direct_answer",
                query_complexity="simple",
                estimated_api_calls=1
            )
        
        # æ¨¡ç³Šåˆ¤æ–·
        vague_words = ["é‚£å€‹", "é€™å€‹", "ä¹‹å‰", "å‰›æ‰", "çš„é‚£å€‹"]
        if any(v in question for v in vague_words) or q_len < 5:
            return QuestionClassification(
                intent=QuestionIntent.CLARIFICATION_NEEDED,
                confidence=0.7,
                reasoning=f"è¦å‰‡åˆ¤æ–·: å•é¡Œæ¨¡ç³Š ({reason})",
                requires_documents=False,
                requires_context=True,
                suggested_strategy="ask_clarification",
                query_complexity="simple",
                estimated_api_calls=2,
                clarification_question="èƒ½å¦æ›´å…·é«”åœ°èªªæ˜æ‚¨çš„å•é¡Œ?",
                suggested_responses=["è©³ç´°æè¿°å•é¡Œ", "æä¾›æ›´å¤šä¿¡æ¯"]
            )
        
        # é»˜èªç‚ºæ–‡æª”æœç´¢
        return QuestionClassification(
            intent=QuestionIntent.DOCUMENT_SEARCH,
            confidence=0.6,
            reasoning=f"è¦å‰‡å›é€€åˆ¤æ–· ({reason})",
            requires_documents=True,
            requires_context=False,
            suggested_strategy="standard_search",
            query_complexity="moderate",
            estimated_api_calls=3
        )
    
    async def generate_clarification_question(
        self,
        original_question: str,
        ambiguity_reason: str,
        db: Optional[AsyncIOMotorDatabase] = None,
        user_id: Optional[str] = None,
        conversation_id: Optional[str] = None
    ) -> dict:
        """
        ç”Ÿæˆæ¾„æ¸…å•é¡Œ(å¸¶å°è©±æ­·å²)
        
        Args:
            original_question: åŸå§‹å•é¡Œ
            ambiguity_reason: æ¨¡ç³Šçš„åŸå› 
            db: æ•¸æ“šåº«é€£æ¥
            user_id: ç”¨æˆ¶ID
            conversation_id: å°è©±ID
            
        Returns:
            dict: åŒ…å«æ¾„æ¸…å•é¡Œå’Œå»ºè­°å›ç­”çš„å­—å…¸
        """
        # è¼‰å…¥å°è©±æ­·å²
        conversation_history_text = ""
        if conversation_id and user_id and db is not None:
            from app.services.qa_workflow.unified_context_helper import unified_context_helper
            
            conversation_history_text = await unified_context_helper.load_and_format_conversation_history(
                db=db,
                conversation_id=conversation_id,
                user_id=user_id,
                limit=10,  # å¢åŠ åˆ°10æ¢ï¼Œç¢ºä¿å¤šè¼ªæ¾„æ¸…ä¸ä¸Ÿå¤±ä¸Šä¸‹æ–‡
                max_content_length=1500  # å¢åŠ åˆ°1500ï¼Œä¿ç•™å®Œæ•´ä¿¡æ¯
            )
            
            if conversation_history_text:
                logger.info("ç”Ÿæˆæ¾„æ¸…å•é¡Œæ™‚å·²è¼‰å…¥å°è©±æ­·å²")
        
        try:
            ai_request = AIRequest(
                task_type=TaskType.GENERATE_CLARIFICATION_QUESTION,
                content=original_question,
                model_preference=self.config.model,
                prompt_params={
                    "user_question": original_question,
                    "ambiguity_reason": ambiguity_reason,
                    "conversation_history": conversation_history_text or "ç„¡å°è©±æ­·å²"
                },
                user_id=user_id
            )
            
            response = await unified_ai_service_simplified.process_request(ai_request, db)
            
            if response.success and response.output_data:
                return response.output_data
            else:
                logger.error(f"ç”Ÿæˆæ¾„æ¸…å•é¡Œå¤±æ•—: {response.error_message}")
                return {
                    "clarification_question": "èƒ½å¦è«‹æ‚¨æä¾›æ›´å¤šç´°ç¯€?",
                    "reasoning": "AIç”Ÿæˆå¤±æ•—,ä½¿ç”¨é»˜èªæ¾„æ¸…å•é¡Œ",
                    "suggested_responses": ["æä¾›æ›´å¤šä¿¡æ¯", "è©³ç´°èªªæ˜"],
                    "missing_information": ["å…·é«”å…§å®¹"]
                }
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ¾„æ¸…å•é¡Œç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return {
                "clarification_question": "èƒ½å¦è«‹æ‚¨æä¾›æ›´å¤šç´°ç¯€?",
                "reasoning": f"éŒ¯èª¤: {str(e)}",
                "suggested_responses": ["æä¾›æ›´å¤šä¿¡æ¯"],
                "missing_information": []
            }


# å‰µå»ºå…¨å±€å¯¦ä¾‹
question_classifier_service = QuestionClassifierService()

