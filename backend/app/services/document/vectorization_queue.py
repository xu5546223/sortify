"""
å‘é‡åŒ–ä»»åŠ¡é˜Ÿåˆ—
ç”¨äºç®¡ç†æ–‡æ¡£å‘é‡åŒ–çš„å¹¶å‘å’Œé¡ºåº
"""

import asyncio
import logging
from typing import List, Dict, Any
from datetime import datetime
from motor.motor_asyncio import AsyncIOMotorDatabase
import uuid

from app.core.logging_utils import AppLogger, log_event, LogLevel

logger = AppLogger(__name__, level=logging.DEBUG).get_logger()


class VectorizationQueue:
    """
    å‘é‡åŒ–ä»»åŠ¡é˜Ÿåˆ—
    
    ç‰¹æ€§ï¼š
    1. æ§åˆ¶å¹¶å‘æ•°é‡ï¼ˆæœ€å¤šåŒæ—¶å¤„ç† N ä¸ªæ–‡ä»¶ï¼‰
    2. æŒ‰é¡ºåºå¤„ç†ä»»åŠ¡ï¼ˆFIFOï¼‰
    3. æä¾›ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢
    4. æ”¯æŒä»»åŠ¡æ‰¹é‡å¤„ç†ä¼˜åŒ–
    """
    
    def __init__(self, max_concurrent_tasks: int = 2):
        """
        åˆå§‹åŒ–é˜Ÿåˆ—
        
        Args:
            max_concurrent_tasks: æœ€å¤šåŒæ—¶å¤„ç†çš„ä»»åŠ¡æ•°é‡
        """
        self.max_concurrent_tasks = max_concurrent_tasks
        self.queue: asyncio.Queue = asyncio.Queue()
        self.active_tasks: Dict[str, Dict[str, Any]] = {}
        self.completed_tasks: List[Dict[str, Any]] = []
        self.processing = False
        self._worker_tasks: List[asyncio.Task] = []
        
        logger.info(f"å‘é‡åŒ–é˜Ÿåˆ—åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å¹¶å‘æ•°: {max_concurrent_tasks}")
    
    async def add_task(self, document_id: str, db: AsyncIOMotorDatabase) -> None:
        """
        æ·»åŠ å‘é‡åŒ–ä»»åŠ¡åˆ°é˜Ÿåˆ—
        
        Args:
            document_id: æ–‡æ¡£IDï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰
            db: æ•°æ®åº“è¿æ¥
        """
        task_info = {
            "document_id": document_id,
            "db": db,
            "added_at": datetime.now(),
            "status": "queued"
        }
        
        await self.queue.put(task_info)
        logger.info(f"âœ… æ–‡æ¡£ {document_id} å·²åŠ å…¥å‘é‡åŒ–é˜Ÿåˆ—ï¼Œå½“å‰é˜Ÿåˆ—é•¿åº¦: {self.queue.qsize()}")
        
        await log_event(
            db=db,
            level=LogLevel.INFO,
            message=f"æ–‡æ¡£ {document_id} åŠ å…¥å‘é‡åŒ–é˜Ÿåˆ—",
            source="vectorization_queue.add_task",
            details={
                "document_id": document_id,
                "queue_size": self.queue.qsize(),
                "active_tasks": len(self.active_tasks)
            }
        )
        
        # å¦‚æœå¤„ç†å™¨æœªè¿è¡Œï¼Œå¯åŠ¨å®ƒ
        if not self.processing:
            await self.start_processing()
    
    async def start_processing(self) -> None:
        """å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨"""
        if self.processing:
            logger.debug("ä»»åŠ¡å¤„ç†å™¨å·²åœ¨è¿è¡Œ")
            return
        
        self.processing = True
        logger.info(f"ğŸš€ å¯åŠ¨å‘é‡åŒ–ä»»åŠ¡å¤„ç†å™¨ï¼Œå¹¶å‘æ•°: {self.max_concurrent_tasks}")
        
        # åˆ›å»ºå¤šä¸ª worker
        self._worker_tasks = [
            asyncio.create_task(self._worker(i))
            for i in range(self.max_concurrent_tasks)
        ]
    
    async def _worker(self, worker_id: int) -> None:
        """
        ä»»åŠ¡å¤„ç† worker
        
        Args:
            worker_id: Worker ID
        """
        logger.info(f"Worker {worker_id} å¯åŠ¨")
        
        while self.processing:
            try:
                # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼ˆè¶…æ—¶æœºåˆ¶ï¼‰
                task_info = await asyncio.wait_for(
                    self.queue.get(),
                    timeout=5.0
                )
                
                document_id = task_info["document_id"]
                db = task_info["db"]
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                self.active_tasks[document_id] = {
                    **task_info,
                    "status": "processing",
                    "worker_id": worker_id,
                    "started_at": datetime.now()
                }
                
                logger.info(f"âš™ï¸ Worker {worker_id} å¼€å§‹å¤„ç†æ–‡æ¡£ {document_id}")
                
                # æ‰§è¡Œå‘é‡åŒ–
                from app.services.document.semantic_summary_service import semantic_summary_service
                
                result = await semantic_summary_service.batch_process_documents(
                    db=db,
                    document_ids=[document_id]
                )
                
                # è®°å½•å®Œæˆ
                completed_info = {
                    **self.active_tasks[document_id],
                    "status": "completed",
                    "completed_at": datetime.now(),
                    "result": result
                }
                
                self.completed_tasks.append(completed_info)
                del self.active_tasks[document_id]
                
                logger.info(f"âœ… Worker {worker_id} å®Œæˆæ–‡æ¡£ {document_id} çš„å‘é‡åŒ–")
                
                await log_event(
                    db=db,
                    level=LogLevel.INFO,
                    message=f"æ–‡æ¡£ {document_id} å‘é‡åŒ–å®Œæˆ",
                    source="vectorization_queue.worker",
                    details={
                        "document_id": document_id,
                        "worker_id": worker_id,
                        "result": result
                    }
                )
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.queue.task_done()
                
            except asyncio.TimeoutError:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                continue
            except Exception as e:
                logger.error(f"âŒ Worker {worker_id} å¤„ç†å¤±è´¥: {e}", exc_info=True)
                
                if document_id in self.active_tasks:
                    failed_info = {
                        **self.active_tasks[document_id],
                        "status": "failed",
                        "error": str(e),
                        "failed_at": datetime.now()
                    }
                    self.completed_tasks.append(failed_info)
                    del self.active_tasks[document_id]
                
                self.queue.task_done()
    
    async def stop_processing(self) -> None:
        """åœæ­¢ä»»åŠ¡å¤„ç†å™¨"""
        if not self.processing:
            return
        
        logger.info("åœæ­¢å‘é‡åŒ–ä»»åŠ¡å¤„ç†å™¨")
        self.processing = False
        
        # ç­‰å¾…æ‰€æœ‰ worker å®Œæˆ
        for task in self._worker_tasks:
            task.cancel()
        
        await asyncio.gather(*self._worker_tasks, return_exceptions=True)
        self._worker_tasks = []
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        return {
            "processing": self.processing,
            "queue_size": self.queue.qsize(),
            "active_tasks": len(self.active_tasks),
            "completed_tasks": len(self.completed_tasks),
            "max_concurrent": self.max_concurrent_tasks,
            "active_task_ids": list(self.active_tasks.keys())
        }


# å…¨å±€å‘é‡åŒ–é˜Ÿåˆ—å®ä¾‹
vectorization_queue = VectorizationQueue(max_concurrent_tasks=2)

