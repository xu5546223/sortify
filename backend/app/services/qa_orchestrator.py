"""
QA ç·¨æ’å™¨æœå‹™

è¼•é‡ç´šç·¨æ’å±¤ï¼Œçµ„åˆç¾æœ‰çš„æ¨¡å¡ŠåŒ–æœå‹™ï¼Œçµ±ä¸€é›»è…¦ç«¯å’Œæ‰‹æ©Ÿç«¯ QA é‚è¼¯ã€‚

è·è²¬ï¼š
- å”èª¿å•é¡Œåˆ†é¡ã€æœç´¢ã€ç­”æ¡ˆç”Ÿæˆç­‰æœå‹™
- å¯¦ç¾æ™ºèƒ½è·¯ç”±ï¼ˆæ ¹æ“šæ„åœ–åˆ†æ´¾åˆ°ä¸åŒè™•ç†å™¨ï¼‰
- å¯¦ç¾æ¨™æº– QA æµç¨‹
- ä¿æŒèˆ‡ç¾æœ‰ API çš„å‘å¾Œå…¼å®¹

é·ç§»è‡ª enhanced_ai_qa_serviceï¼Œä½†æ¡ç”¨çµ„åˆè€Œéç¹¼æ‰¿çš„è¨­è¨ˆæ¨¡å¼ã€‚
"""

import logging
import time
import json
import asyncio
from typing import Optional, List, Dict, Any, Tuple, AsyncGenerator
from motor.motor_asyncio import AsyncIOMotorDatabase

from app.core.logging_utils import AppLogger, log_event, LogLevel
from app.models.vector_models import (
    AIQARequest, AIQAResponse, QueryRewriteResult, 
    SemanticSearchResult, SemanticContextDocument, LLMContextDocument
)
from app.models.question_models import QuestionIntent
from app.core.config import settings

# å°å…¥å·²æœ‰æœå‹™
from app.services.qa_core.qa_query_rewriter import qa_query_rewriter
from app.services.qa_core.qa_search_coordinator import qa_search_coordinator
from app.services.qa_core.qa_answer_service import qa_answer_service
from app.services.qa_workflow.question_classifier_service import question_classifier_service
from app.services.qa_workflow.context_loader_service import context_loader_service
from app.services.qa.utils.search_strategy import extract_search_strategy

# å°å…¥æ„åœ–è™•ç†å™¨
from app.services.intent_handlers.greeting_handler import greeting_handler
from app.services.intent_handlers.clarification_handler import clarification_handler
from app.services.intent_handlers.simple_factual_handler import simple_factual_handler
from app.services.intent_handlers.document_search_handler import document_search_handler
from app.services.intent_handlers.document_detail_query_handler import document_detail_query_handler
from app.services.intent_handlers.complex_analysis_handler import complex_analysis_handler

logger = AppLogger(__name__, level=logging.DEBUG).get_logger()


class StreamEvent:
    """æµå¼äº‹ä»¶ - ç”¨æ–¼æ‰‹æ©Ÿç«¯ SSE è¼¸å‡º"""
    
    def __init__(self, event_type: str, data: dict):
        self.type = event_type
        self.data = data
    
    def to_sse(self) -> str:
        """è½‰æ›ç‚º SSE æ ¼å¼"""
        event_data = {'type': self.type, **self.data}
        return f"data: {json.dumps(event_data, ensure_ascii=False)}\n\n"


class QAOrchestrator:
    """
    QA ç·¨æ’å™¨ - è¼•é‡ç´šå”èª¿å±¤
    
    ä½¿ç”¨çµ„åˆæ¨¡å¼æ•´åˆå·²æœ‰çš„æ¨¡å¡ŠåŒ–æœå‹™ï¼Œé¿å…é‡è¤‡å¯¦ç¾æ¥­å‹™é‚è¼¯ã€‚
    """
    
    def __init__(self):
        """åˆå§‹åŒ–ç·¨æ’å™¨ï¼Œæ³¨å…¥å·²æœ‰æœå‹™"""
        # æ ¸å¿ƒæœå‹™ï¼ˆå·²å¯¦ä¾‹åŒ–çš„å…¨å±€æœå‹™ï¼‰
        self.query_rewriter = qa_query_rewriter
        self.search_coordinator = qa_search_coordinator
        self.answer_service = qa_answer_service
        self.classifier = question_classifier_service
        self.context_loader = context_loader_service
        
        # æ„åœ–è™•ç†å™¨æ˜ å°„
        self.intent_handlers = {
            QuestionIntent.GREETING: greeting_handler,
            QuestionIntent.CHITCHAT: greeting_handler,
            QuestionIntent.CLARIFICATION_NEEDED: clarification_handler,
            QuestionIntent.SIMPLE_FACTUAL: simple_factual_handler,
            QuestionIntent.DOCUMENT_SEARCH: document_search_handler,
            QuestionIntent.DOCUMENT_DETAIL_QUERY: document_detail_query_handler,
            QuestionIntent.COMPLEX_ANALYSIS: complex_analysis_handler,
        }
        
        # é…ç½®
        self.enable_intelligent_routing = getattr(settings, 'ENABLE_INTELLIGENT_ROUTING', True)
        
        logger.info(f"QA ç·¨æ’å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ™ºèƒ½è·¯ç”±: {self.enable_intelligent_routing}")
    
    async def process_qa_request_intelligent(
        self,
        db: AsyncIOMotorDatabase,
        request: AIQARequest,
        user_id: Optional[str] = None,
        request_id: Optional[str] = None
    ) -> AIQAResponse:
        """
        æ™ºèƒ½å•ç­”è™•ç†å…¥å£ - æ ¹æ“šå•é¡Œæ„åœ–å‹•æ…‹è·¯ç”±
        
        æµç¨‹:
        1. å¿«é€Ÿæ„åœ–åˆ†é¡
        2. æ ¹æ“šæ„åœ–è·¯ç”±åˆ°å°æ‡‰çš„è™•ç†å™¨
        3. å»¶é²è¼‰å…¥å¿…è¦çš„ä¸Šä¸‹æ–‡
        4. è¿”å›å„ªåŒ–çš„å›ç­”
        
        Args:
            db: æ•¸æ“šåº«é€£æ¥
            request: AI QA è«‹æ±‚
            user_id: ç”¨æˆ¶ID
            request_id: è«‹æ±‚ID
            
        Returns:
            AIQAResponse: å•ç­”éŸ¿æ‡‰
        """
        start_time = time.time()
        
        logger.info(f"ğŸš€ [ç·¨æ’å™¨] æ™ºèƒ½å•ç­”è«‹æ±‚: {request.question[:100]}...")
        
        # æª¢æŸ¥æ˜¯å¦è·³éæ™ºèƒ½è·¯ç”±
        if not self.enable_intelligent_routing or getattr(request, 'skip_classification', False):
            logger.info("æ™ºèƒ½è·¯ç”±å·²ç¦ç”¨æˆ–è¢«è·³é,ä½¿ç”¨æ¨™æº–æµç¨‹")
            return await self.process_qa_request(db, request, user_id, request_id)
        
        try:
            # Step 1: è¼‰å…¥å°è©±ä¸Šä¸‹æ–‡ï¼ˆç”¨æ–¼æ„åœ–åˆ†é¡ï¼‰
            from app.services.qa_workflow.unified_context_helper import unified_context_helper
            
            conversation_context = await unified_context_helper.load_conversation_history_list(
                db=db,
                conversation_id=request.conversation_id,
                user_id=str(user_id) if user_id else None,
                limit=10
            )
            
            # Step 1.5: ç²å–ç·©å­˜æ–‡æª”ä¿¡æ¯ï¼ˆç”¨æ–¼åˆ†é¡ï¼‰
            cached_documents_info_for_classifier = None
            if request.conversation_id and user_id:
                cached_documents_info_for_classifier = await self._get_cached_documents_info(
                    db, request.conversation_id, user_id
                )
            
            # Step 2: å¿«é€Ÿæ„åœ–åˆ†é¡
            classification = await self.classifier.classify_question(
                question=request.question,
                conversation_history=conversation_context,
                has_cached_documents=bool(request.conversation_id),
                cached_documents_info=cached_documents_info_for_classifier,
                db=db,
                user_id=str(user_id) if user_id else None
            )
            
            logger.info(
                f"ğŸ“Š å•é¡Œåˆ†é¡å®Œæˆ: intent={classification.intent}, "
                f"confidence={classification.confidence:.2f}, "
                f"strategy={classification.suggested_strategy}"
            )
            
            # Step 3: æ ¹æ“šæ„åœ–è·¯ç”±åˆ°å°æ‡‰è™•ç†å™¨
            handler = self.intent_handlers.get(classification.intent)
            
            if handler:
                logger.info(f"â†’ è·¯ç”±åˆ°: {handler.__class__.__name__ if hasattr(handler, '__class__') else classification.intent}")
                
                # å»¶é²è¼‰å…¥ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                context = await self._load_context_if_needed(
                    db, request, user_id, classification
                )
                
                return await handler.handle(
                    request, classification, context, db, user_id, request_id
                )
            else:
                logger.warning(f"æœªçŸ¥çš„æ„åœ–é¡å‹: {classification.intent}, ä½¿ç”¨æ¨™æº–æµç¨‹")
                return await self.process_qa_request(db, request, user_id, request_id)
                
        except Exception as e:
            logger.error(f"æ™ºèƒ½è·¯ç”±è™•ç†å¤±æ•—,å›é€€åˆ°æ¨™æº–æµç¨‹: {e}", exc_info=True)
            
            # è¨˜éŒ„éŒ¯èª¤
            await log_event(
                db=db,
                level=LogLevel.ERROR,
                message=f"æ™ºèƒ½è·¯ç”±å¤±æ•—: {str(e)}",
                source="service.qa_orchestrator.intelligent_routing_error",
                user_id=str(user_id) if user_id else None,
                request_id=request_id,
                details={"error": str(e), "question": request.question[:100]}
            )
            
            # å›é€€åˆ°æ¨™æº–æµç¨‹
            return await self.process_qa_request(db, request, user_id, request_id)
    
    async def process_qa_request(
        self,
        db: AsyncIOMotorDatabase,
        request: AIQARequest,
        user_id: Optional[str] = None,
        request_id: Optional[str] = None
    ) -> AIQAResponse:
        """
        æ¨™æº– QA æµç¨‹ - ç°¡åŒ–ç‰ˆæœ¬ï¼Œå§”è¨—çµ¦å·²æœ‰æœå‹™
        
        æµç¨‹:
        1. æŸ¥è©¢é‡å¯«
        2. å‘é‡æœç´¢
        3. è™•ç†æ–‡æª”
        4. ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            db: æ•¸æ“šåº«é€£æ¥
            request: AI QA è«‹æ±‚
            user_id: ç”¨æˆ¶ID
            request_id: è«‹æ±‚ID
            
        Returns:
            AIQAResponse: å•ç­”éŸ¿æ‡‰
        """
        user_id_str = str(user_id) if user_id else None
        start_time = time.time()
        total_tokens = 0
        
        logger.info(f"ğŸ“ [ç·¨æ’å™¨] æ¨™æº– QA æµç¨‹: {request.question[:100]}...")
        
        await log_event(
            db=db, level=LogLevel.INFO,
            message="QA Orchestrator: Standard flow started",
            source="service.qa_orchestrator.process_qa_request",
            user_id=user_id_str, request_id=request_id,
            details={"question_length": len(request.question) if request.question else 0}
        )
        
        try:
            # Step 1: æŸ¥è©¢é‡å¯«
            query_rewrite_result, rewrite_tokens = await self.query_rewriter.rewrite_query(
                db=db,
                original_query=request.question,
                user_id=user_id_str,
                request_id=request_id,
                query_rewrite_count=getattr(request, 'query_rewrite_count', 3)
            )
            total_tokens += rewrite_tokens
            
            # Step 2: æ±ºå®šæœç´¢ç­–ç•¥
            search_strategy = extract_search_strategy(query_rewrite_result)
            logger.info(f"ğŸ¯ ä½¿ç”¨æœç´¢ç­–ç•¥: {search_strategy}")
            
            # Step 3: åŸ·è¡Œæœç´¢
            queries = query_rewrite_result.rewritten_queries if query_rewrite_result.rewritten_queries else [request.question]
            
            search_results = await self.search_coordinator.unified_search(
                db=db,
                queries=queries,
                user_id=user_id_str,
                search_strategy=search_strategy,
                top_k=getattr(request, 'max_documents_for_selection', request.context_limit),
                similarity_threshold=getattr(request, 'similarity_threshold', 0.3),
                enable_diversity_optimization=True,
                document_ids=request.document_ids if hasattr(request, 'document_ids') else None
            )
            
            # Step 4: è™•ç†æœç´¢çµæœ
            if not search_results:
                logger.warning("å‘é‡æœç´¢æœªæ‰¾åˆ°ç›¸é—œæ–‡æª”")
                return AIQAResponse(
                    answer="æŠ±æ­‰ï¼Œæˆ‘åœ¨æ‚¨çš„æ–‡æª”åº«ä¸­æ²’æœ‰æ‰¾åˆ°èˆ‡æ‚¨å•é¡Œç›¸é—œçš„å…§å®¹ã€‚",
                    source_documents=[],
                    confidence_score=0.0,
                    tokens_used=total_tokens,
                    processing_time=time.time() - start_time,
                    query_rewrite_result=query_rewrite_result,
                    semantic_search_contexts=[],
                    session_id=request.session_id
                )
            
            # Step 5: æº–å‚™èªç¾©æœç´¢ä¸Šä¸‹æ–‡
            semantic_contexts_for_response: List[SemanticContextDocument] = []
            for res in search_results:
                semantic_contexts_for_response.append(
                    SemanticContextDocument(
                        document_id=res.document_id,
                        summary_or_chunk_text=res.summary_text,
                        similarity_score=res.similarity_score,
                        metadata=res.metadata
                    )
                )
            
            # Step 6: ç²å–å®Œæ•´æ–‡æª”
            from app.crud.crud_documents import get_documents_by_ids
            document_ids = [result.document_id for result in search_results]
            documents = await get_documents_by_ids(db, document_ids)
            
            if not documents:
                logger.warning("ç„¡æ³•ç²å–å®Œæ•´æ–‡æª”")
                return AIQAResponse(
                    answer="æŠ±æ­‰ï¼Œç„¡æ³•ç²å–ç›¸é—œæ–‡æª”çš„è©³ç´°å…§å®¹ã€‚",
                    source_documents=[],
                    confidence_score=0.0,
                    tokens_used=total_tokens,
                    processing_time=time.time() - start_time,
                    query_rewrite_result=query_rewrite_result,
                    semantic_search_contexts=semantic_contexts_for_response,
                    session_id=request.session_id
                )
            
            # Step 7: ç”Ÿæˆç­”æ¡ˆï¼ˆä½¿ç”¨ qa_answer_serviceï¼‰
            answer_result = await self.answer_service.generate_answer(
                db=db,
                original_query=request.question,
                documents_for_context=documents,
                query_rewrite_result=query_rewrite_result,
                detailed_document_data=None,  # æ¨™æº–æµç¨‹ä¸ä½¿ç”¨è©³ç´°æ•¸æ“š
                ai_generated_query_reasoning=None,  # æ¨™æº–æµç¨‹ä¸ä½¿ç”¨ AI æŸ¥è©¢æ¨ç†
                user_id=user_id_str,
                request_id=request_id,
                model_preference=request.model_preference,
                ensure_chinese_output=getattr(request, 'ensure_chinese_output', None),
                conversation_history=None  # å¯ä»¥æ“´å±•æ”¯æŒ
            )
            
            total_tokens += answer_result['tokens_used']
            
            # Step 8: æ§‹å»ºéŸ¿æ‡‰
            processing_time = time.time() - start_time
            
            response = AIQAResponse(
                answer=answer_result['answer'],
                source_documents=answer_result['source_documents'],
                confidence_score=answer_result['confidence_score'],
                tokens_used=total_tokens,
                processing_time=processing_time,
                query_rewrite_result=query_rewrite_result,
                semantic_search_contexts=semantic_contexts_for_response,
                llm_context_documents=answer_result['llm_context_documents'],
                session_id=request.session_id
            )
            
            logger.info(f"âœ… [ç·¨æ’å™¨] QA å®Œæˆï¼Œè€—æ™‚ {processing_time:.2f}sï¼Œtokens={total_tokens}")
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ [ç·¨æ’å™¨] æ¨™æº–æµç¨‹å¤±æ•—: {e}", exc_info=True)
            
            await log_event(
                db=db, level=LogLevel.ERROR,
                message=f"QA Orchestrator failed: {str(e)}",
                source="service.qa_orchestrator.process_qa_request_error",
                user_id=user_id_str, request_id=request_id,
                details={"error": str(e)}
            )
            
            return AIQAResponse(
                answer=f"æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}",
                source_documents=[],
                confidence_score=0.0,
                tokens_used=total_tokens,
                processing_time=time.time() - start_time,
                query_rewrite_result=None,
                semantic_search_contexts=[],
                session_id=request.session_id
            )
    
    async def _get_cached_documents_info(
        self,
        db: AsyncIOMotorDatabase,
        conversation_id: str,
        user_id: str
    ) -> Optional[List[Dict]]:
        """ç²å–ç·©å­˜æ–‡æª”ä¿¡æ¯ç”¨æ–¼åˆ†é¡"""
        try:
            from app.crud import crud_conversations
            from uuid import UUID
            
            conversation_uuid = UUID(conversation_id)
            user_uuid = UUID(str(user_id)) if not isinstance(user_id, UUID) else user_id
            
            # ç²å–ç·©å­˜çš„æ–‡æª”ID
            cached_doc_ids, _ = await crud_conversations.get_cached_documents(
                db=db,
                conversation_id=conversation_uuid,
                user_id=user_uuid
            )
            
            if not cached_doc_ids:
                return None
            
            # ç²å–æ–‡æª”è©³ç´°ä¿¡æ¯
            from app.crud.crud_documents import get_documents_by_ids
            documents = await get_documents_by_ids(db, cached_doc_ids)
            
            # æ§‹å»ºæ–‡æª”ä¿¡æ¯åˆ—è¡¨
            cached_documents_info = []
            for idx, doc in enumerate(documents, 1):
                doc_info = {
                    "document_id": str(doc.id),
                    "filename": doc.filename,
                    "reference_number": idx,
                    "summary": ""
                }
                
                # å®‰å…¨ç²å–æ‘˜è¦
                try:
                    enriched_data = getattr(doc, 'enriched_data', None)
                    if enriched_data and isinstance(enriched_data, dict):
                        doc_info["summary"] = enriched_data.get('summary', '')
                    
                    if not doc_info["summary"] and hasattr(doc, 'analysis') and doc.analysis:
                        if hasattr(doc.analysis, 'ai_analysis_output') and isinstance(doc.analysis.ai_analysis_output, dict):
                            key_info = doc.analysis.ai_analysis_output.get('key_information', {})
                            if isinstance(key_info, dict):
                                doc_info["summary"] = key_info.get('content_summary', '')
                except Exception as e:
                    logger.warning(f"ç²å–æ–‡æª” {idx} æ‘˜è¦å¤±æ•—: {e}")
                
                cached_documents_info.append(doc_info)
            
            logger.info(f"æº–å‚™äº† {len(cached_documents_info)} å€‹ç·©å­˜æ–‡æª”ä¿¡æ¯ç”¨æ–¼åˆ†é¡")
            return cached_documents_info
            
        except Exception as e:
            logger.warning(f"ç²å–ç·©å­˜æ–‡æª”ä¿¡æ¯å¤±æ•—: {e}")
            return None
    
    async def _load_context_if_needed(
        self,
        db: AsyncIOMotorDatabase,
        request: AIQARequest,
        user_id: Optional[str],
        classification
    ) -> Optional[dict]:
        """å»¶é²è¼‰å…¥å°è©±ä¸Šä¸‹æ–‡"""
        try:
            context = await self.context_loader.load_conversation_context_if_needed(
                db=db,
                conversation_id=request.conversation_id,
                user_id=str(user_id) if user_id else None,
                requires_context=classification.requires_context
            )
            
            if context and context.recent_messages:
                logger.info(f"è¼‰å…¥äº† {len(context.recent_messages)} æ¢æ­·å²æ¶ˆæ¯")
            
            # è½‰æ›ç‚ºå­—å…¸æ ¼å¼(ä¿æŒå…¼å®¹æ€§)
            if context:
                return {
                    "conversation_id": context.conversation_id,
                    "recent_messages": context.recent_messages,
                    "cached_document_ids": context.cached_document_ids,
                    "cached_document_data": context.cached_document_data,
                    "message_count": context.message_count
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"è¼‰å…¥ä¸Šä¸‹æ–‡å¤±æ•—,ç¹¼çºŒè™•ç†: {e}")
            return None


    async def process_qa_request_intelligent_stream(
        self,
        db: AsyncIOMotorDatabase,
        request: AIQARequest,
        user_id: Optional[str] = None,
        request_id: Optional[str] = None
    ) -> AsyncGenerator[StreamEvent, None]:
        """
        æ™ºèƒ½å•ç­”è™•ç† - æµå¼ç‰ˆæœ¬ï¼ˆæ‰‹æ©Ÿç«¯ï¼‰
        
        ä¿æŒèˆ‡ç¾æœ‰æ‰‹æ©Ÿç«¯å®Œå…¨ä¸€è‡´çš„äº‹ä»¶æ ¼å¼å’Œæµç¨‹ï¼š
        1. ç™¼é€é€²åº¦äº‹ä»¶ï¼ˆåˆ†é¡ã€æœç´¢ç­‰ï¼‰
        2. åœ¨ç­”æ¡ˆç”Ÿæˆéšæ®µä½¿ç”¨ generate_answer_stream() çœŸå¯¦æµå¼è¼¸å‡º
        3. æ”¯æŒæ‰¹å‡†æµç¨‹ï¼ˆapproval_neededï¼‰
        4. æ”¯æŒæ¾„æ¸…è™•ç†ï¼ˆclarification_textï¼‰
        
        Yields:
            StreamEvent: æµå¼äº‹ä»¶ï¼ˆprogress, chunk, metadata, complete, error, approval_neededï¼‰
        """
        try:
            # æª¢æŸ¥æ˜¯å¦æ˜¯æ‰¹å‡†æ“ä½œï¼ˆæ‰¹å‡†å¾Œä¸ç™¼é€é‡è¤‡çš„é€²åº¦äº‹ä»¶ï¼‰
            is_approval_action = getattr(request, 'workflow_action', None) in [
                'approve_search', 'skip_search', 
                'approve_detail_query', 'skip_detail_query'
            ]
            
            # === ç™¼é€é–‹å§‹äº‹ä»¶ï¼ˆæ‰¹å‡†æ“ä½œè·³éï¼‰===
            if not is_approval_action:
                yield StreamEvent('progress', {
                    'stage': 'start',
                    'message': 'ğŸš€ é–‹å§‹è™•ç†æ‚¨çš„å•é¡Œ...'
                })
                await asyncio.sleep(0.05)
            
            # === æ­¥é©Ÿ 1: è¼‰å…¥å°è©±ä¸Šä¸‹æ–‡ ===
            from app.services.qa_workflow.unified_context_helper import unified_context_helper
            
            conversation_context = None
            cached_documents_info_for_classifier = None
            
            if request.conversation_id:
                conversation_context = await unified_context_helper.load_conversation_history_list(
                    db=db,
                    conversation_id=request.conversation_id,
                    user_id=str(user_id) if user_id else None,
                    limit=10
                )
                
                if conversation_context:
                    logger.info(f"è¼‰å…¥äº† {len(conversation_context)} æ¢æ­·å²æ¶ˆæ¯")
                
                # ç²å–ç·©å­˜æ–‡æª”ä¿¡æ¯
                cached_documents_info_for_classifier = await self._get_cached_documents_info(
                    db, request.conversation_id, user_id
                )
            
            # === æ­¥é©Ÿ 1.5: è™•ç†æ¾„æ¸…å›ç­” ===
            effective_question = request.question
            if getattr(request, 'workflow_action', None) == 'provide_clarification' and getattr(request, 'clarification_text', None):
                logger.info(f"ğŸ“ æ”¶åˆ°æ¾„æ¸…å›ç­”: {request.clarification_text}")
                
                # ä¿å­˜æ¾„æ¸…å›ç­”åˆ°å°è©±
                if request.conversation_id:
                    from app.crud import crud_conversations
                    from uuid import UUID
                    try:
                        conversation_uuid = UUID(request.conversation_id)
                        user_uuid = UUID(str(user_id)) if not isinstance(user_id, UUID) else user_id
                        
                        await crud_conversations.add_message_to_conversation(
                            db=db,
                            conversation_id=conversation_uuid,
                            user_id=user_uuid,
                            role="user",
                            content=request.clarification_text,
                            tokens_used=None
                        )
                        
                        # ä½¿ç·©å­˜å¤±æ•ˆä¸¦é‡æ–°è¼‰å…¥
                        from app.services.cache.conversation_cache_service import conversation_cache_service
                        await conversation_cache_service.invalidate_conversation(
                            user_id=user_uuid,
                            conversation_id=conversation_uuid
                        )
                        
                        conversation_context = await unified_context_helper.load_conversation_history_list(
                            db=db,
                            conversation_id=request.conversation_id,
                            user_id=str(user_id) if user_id else None,
                            limit=10
                        )
                    except Exception as e:
                        logger.error(f"âŒ ä¿å­˜æ¾„æ¸…å›ç­”å¤±æ•—: {e}")
                
                effective_question = f"{request.question} â†’ {request.clarification_text}"
            
            # === æ­¥é©Ÿ 2: å•é¡Œåˆ†é¡ï¼ˆæ‰¹å‡†æ“ä½œè·³éé€²åº¦ç™¼é€ï¼‰===
            if not is_approval_action:
                yield StreamEvent('progress', {
                    'stage': 'classifying',
                    'message': 'ğŸ¯ AI æ­£åœ¨åˆ†æå•é¡Œæ„åœ–...'
                })
                await asyncio.sleep(0.05)
            
            classification = await self.classifier.classify_question(
                question=effective_question,
                conversation_history=conversation_context,
                has_cached_documents=bool(request.conversation_id),
                cached_documents_info=cached_documents_info_for_classifier,
                db=db,
                user_id=str(user_id) if user_id else None
            )
            
            # ç™¼é€åˆ†é¡çµæœï¼ˆæ‰¹å‡†æ“ä½œè·³éï¼‰
            if not is_approval_action:
                intent_label = {
                    QuestionIntent.GREETING: 'å¯’æš„',
                    QuestionIntent.CHITCHAT: 'é–’èŠ',
                    QuestionIntent.DOCUMENT_SEARCH: 'æ–‡æª”æœç´¢',
                    QuestionIntent.SIMPLE_FACTUAL: 'ç°¡å–®æŸ¥è©¢',
                    QuestionIntent.COMPLEX_ANALYSIS: 'è¤‡é›œåˆ†æ',
                    QuestionIntent.CLARIFICATION_NEEDED: 'éœ€è¦æ¾„æ¸…',
                    QuestionIntent.DOCUMENT_DETAIL_QUERY: 'MongoDB è©³ç´°æŸ¥è©¢'
                }.get(classification.intent, str(classification.intent))
                
                yield StreamEvent('progress', {
                    'stage': 'classified',
                    'message': f'âœ… å•é¡Œåˆ†é¡ï¼š{intent_label}ï¼ˆç½®ä¿¡åº¦ {classification.confidence:.0%}ï¼‰'
                })
                await asyncio.sleep(0.1)
                
                # ç™¼é€æ¨ç†å…§å®¹
                if hasattr(classification, 'reasoning') and classification.reasoning:
                    yield StreamEvent('progress', {
                        'stage': 'reasoning',
                        'message': f'ğŸ’­ AI æ¨ç†',
                        'detail': classification.reasoning
                    })
                    await asyncio.sleep(0.05)
            
            # === æ­¥é©Ÿ 3: è·¯ç”±åˆ°è™•ç†å™¨ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰===
            handler = self.intent_handlers.get(classification.intent)
            
            if not handler:
                yield StreamEvent('error', {'message': f'æœªçŸ¥çš„æ„åœ–é¡å‹: {classification.intent}'})
                return
            
            logger.info(f"â†’ è·¯ç”±åˆ°: {handler.__class__.__name__ if hasattr(handler, '__class__') else classification.intent}")
            
            # è¼‰å…¥ä¸Šä¸‹æ–‡
            context = await self._load_context_if_needed(
                db, request, user_id, classification
            )
            
            # æª¢æŸ¥ handler æ˜¯å¦æœ‰æµå¼ç‰ˆæœ¬
            if hasattr(handler, 'handle_stream'):
                # ä½¿ç”¨æµå¼è™•ç†å™¨
                async for event in handler.handle_stream(
                    request, classification, context, db, user_id, request_id
                ):
                    yield event
            else:
                # ä½¿ç”¨æ™®é€šè™•ç†å™¨ï¼Œæ ¹æ“šæ„åœ–é¡å‹æ±ºå®šåƒæ•¸
                # ç°¡å–®æ„åœ–è™•ç†
                if classification.intent in [QuestionIntent.GREETING, QuestionIntent.CHITCHAT]:
                    # ç°¡å–®æ„åœ–ç›´æ¥è™•ç†ï¼ˆcontext = Noneï¼‰
                    response = await handler.handle(
                        request, classification, None, db, user_id, request_id
                    )
                    yield StreamEvent('complete', {'answer': response.answer})
                    
                elif classification.intent == QuestionIntent.CLARIFICATION_NEEDED:
                    # éœ€è¦æ¾„æ¸…ï¼ˆå¯ä»¥ä½¿ç”¨ context ç”Ÿæˆæ›´å¥½çš„æ¾„æ¸…å•é¡Œï¼‰
                    response = await handler.handle(
                        request, classification, context, db, user_id, request_id
                    )
                    # ç™¼é€æ¾„æ¸…è«‹æ±‚ï¼ŒåŒ…å«å®Œæ•´ä¿¡æ¯
                    approval_data = {
                        'workflow_state': response.workflow_state,
                        'classification': response.classification.model_dump() if response.classification else None,
                        'next_action': response.next_action,
                        'pending_approval': response.pending_approval
                    }
                    yield StreamEvent('approval_needed', approval_data)
                    
                elif classification.intent == QuestionIntent.SIMPLE_FACTUAL:
                    # ç°¡å–®äº‹å¯¦æŸ¥è©¢ï¼ˆcontext = Noneï¼‰
                    response = await handler.handle(
                        request, classification, None, db, user_id, request_id
                    )
                    if response.answer:
                        yield StreamEvent('complete', {'answer': response.answer})
                    else:
                        yield StreamEvent('error', {'message': 'è™•ç†å¤±æ•—'})
                else:
                    # å…¶ä»–æ„åœ–ï¼ˆDOCUMENT_SEARCH, DOCUMENT_DETAIL_QUERY, COMPLEX_ANALYSISï¼‰éœ€è¦ context
                    # å¦‚æœ handler æ²’æœ‰å¯¦ç¾ handle_streamï¼Œç›´æ¥èª¿ç”¨ handle
                    
                    # å¦‚æœæ˜¯æ‰¹å‡†æ“ä½œï¼Œå…ˆåŸ·è¡Œé è™•ç†ä¸¦ç«‹å³åé¥‹
                    if is_approval_action and classification.intent == QuestionIntent.DOCUMENT_SEARCH:
                        yield StreamEvent('progress', {
                            'stage': 'query_rewriting',
                            'message': 'ğŸ”„ æ­£åœ¨å„ªåŒ–æŸ¥è©¢èªå¥...'
                        })
                        await asyncio.sleep(0.05)
                        
                        # åŸ·è¡ŒæŸ¥è©¢é‡å¯«
                        from app.services.qa_core.qa_query_rewriter import qa_query_rewriter
                        query_rewrite_result, rewrite_tokens = await qa_query_rewriter.rewrite_query(
                            db=db,
                            original_query=request.question,
                            user_id=user_id,
                            request_id=request_id
                        )
                        
                        # ç«‹å³ç™¼é€æŸ¥è©¢é‡å¯«çµæœ
                        if query_rewrite_result and query_rewrite_result.rewritten_queries:
                            yield StreamEvent('progress', {
                                'stage': 'query_rewriting',
                                'message': f'âœ¨ å·²å„ªåŒ–æŸ¥è©¢ï¼ˆç”Ÿæˆ {len(query_rewrite_result.rewritten_queries)} å€‹ï¼‰',
                                'detail': {
                                    'queries': query_rewrite_result.rewritten_queries,
                                    'count': len(query_rewrite_result.rewritten_queries)
                                }
                            })
                            await asyncio.sleep(0.05)
                    
                    # å¦‚æœæ˜¯è©³ç´°æŸ¥è©¢æ‰¹å‡†ï¼Œç™¼é€ MongoDB æŸ¥è©¢é€²åº¦
                    if is_approval_action and classification.intent == QuestionIntent.DOCUMENT_DETAIL_QUERY:
                        yield StreamEvent('progress', {
                            'stage': 'mongodb_query',
                            'message': 'ğŸ” æ­£åœ¨åŸ·è¡Œ MongoDB è©³ç´°æŸ¥è©¢...'
                        })
                        await asyncio.sleep(0.05)
                    
                    # èª¿ç”¨ handlerï¼ˆé€™äº› handlers æ¥å— context åƒæ•¸ï¼‰
                    response = await handler.handle(
                        request, classification, context, db, user_id, request_id
                    )
                    
                    # ç™¼é€å®Œæˆé€²åº¦
                    if is_approval_action:
                        # å¦‚æœæ˜¯æ–‡æª”æœç´¢ï¼Œé¡¯ç¤ºæ‰¾åˆ°çš„æ–‡æª”æ•¸
                        if classification.intent == QuestionIntent.DOCUMENT_SEARCH and response.source_documents:
                            doc_count = len(response.source_documents)
                            yield StreamEvent('progress', {
                                'stage': 'vector_search',
                                'message': f'âœ… å·²æœç´¢åˆ° {doc_count} å€‹ç›¸é—œæ–‡æª”'
                            })
                            await asyncio.sleep(0.05)
                        
                        # å¦‚æœæ˜¯è©³ç´°æŸ¥è©¢ï¼Œé¡¯ç¤º MongoDB æŸ¥è©¢çµæœ
                        elif classification.intent == QuestionIntent.DOCUMENT_DETAIL_QUERY:
                            # å¾ response ä¸­æå–è©³ç´°æ•¸æ“šä¿¡æ¯
                            detail_info = {}
                            mongodb_data = []
                            
                            if hasattr(response, 'semantic_search_contexts') and response.semantic_search_contexts:
                                detail_info['queried_documents'] = len(response.semantic_search_contexts)
                                # è¨ˆç®—ç¸½æ¬„ä½æ•¸ä¸¦æ”¶é›†æ•¸æ“š
                                total_fields = 0
                                for ctx in response.semantic_search_contexts:
                                    if ctx.metadata:
                                        if 'fields_count' in ctx.metadata:
                                            total_fields += ctx.metadata['fields_count']
                                        # å°‡å®Œæ•´çš„ context æ•¸æ“šæ·»åŠ åˆ° mongodb_data
                                        mongodb_data.append({
                                            'document_id': ctx.document_id,
                                            'metadata': ctx.metadata
                                        })
                                detail_info['total_fields'] = total_fields
                            
                            if response.source_documents:
                                detail_info['source_documents'] = len(response.source_documents)
                            
                            # åŒ…å«å¯¦éš›çš„ MongoDB æŸ¥è©¢æ•¸æ“š
                            if mongodb_data:
                                detail_info['mongodb_data'] = mongodb_data
                            
                            message = f'âœ… MongoDB æŸ¥è©¢å®Œæˆ'
                            if detail_info.get('queried_documents'):
                                message += f"ï¼ˆæŸ¥è©¢ {detail_info['queried_documents']} å€‹æ–‡æª”"
                                if detail_info.get('total_fields'):
                                    message += f"ï¼Œæå– {detail_info['total_fields']} å€‹æ¬„ä½"
                                message += "ï¼‰"
                            
                            yield StreamEvent('progress', {
                                'stage': 'mongodb_query',
                                'message': message,
                                'detail': detail_info
                            })
                            await asyncio.sleep(0.05)
                    
                    # æª¢æŸ¥æ˜¯å¦éœ€è¦æ‰¹å‡†ï¼ˆpending_approval æ˜¯ response çš„ç›´æ¥å±¬æ€§ï¼‰
                    if response.pending_approval or (response.workflow_state and response.workflow_state.get('pending_approval')):
                        logger.info(f"éœ€è¦æ‰¹å‡†: {response.pending_approval or response.workflow_state.get('pending_approval')}")
                        # ç™¼é€æ‰¹å‡†è«‹æ±‚ï¼ŒåŒ…å«å®Œæ•´ä¿¡æ¯
                        approval_data = {
                            'workflow_state': response.workflow_state,
                            'query_rewrite_result': response.query_rewrite_result.model_dump() if response.query_rewrite_result else None,
                            'classification': response.classification.model_dump() if response.classification else None,
                            'next_action': response.next_action,
                            'pending_approval': response.pending_approval
                        }
                        yield StreamEvent('approval_needed', approval_data)
                        # ä¸ç¹¼çºŒè™•ç†ï¼Œç­‰å¾…ç”¨æˆ¶æ‰¹å‡†
                    elif response.answer:
                        # æœ‰ç­”æ¡ˆï¼Œç™¼é€æµå¼è¼¸å‡º
                        # ç™¼é€ç”Ÿæˆé€²åº¦
                        yield StreamEvent('progress', {
                            'stage': 'ai_generating',
                            'message': 'ğŸ¤– AI æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...'
                        })
                        await asyncio.sleep(0.05)
                        
                        # æ¨¡æ“¬æµå¼è¼¸å‡ºç­”æ¡ˆ
                        answer = response.answer
                        chunk_size = 50
                        for i in range(0, len(answer), chunk_size):
                            chunk = answer[i:i+chunk_size]
                            yield StreamEvent('chunk', {'text': chunk})
                            await asyncio.sleep(0.01)
                        
                        # ç™¼é€å…ƒæ•¸æ“š
                        yield StreamEvent('metadata', {
                            'tokens_used': response.tokens_used,
                            'source_documents': response.source_documents if response.source_documents else [],
                            'processing_time': response.processing_time
                        })
                        
                        yield StreamEvent('complete', {'message': 'âœ… è™•ç†å®Œæˆ'})
                    else:
                        # æ²’æœ‰ç­”æ¡ˆä¹Ÿæ²’æœ‰ workflow_stateï¼Œå¯èƒ½æ˜¯éŒ¯èª¤
                        yield StreamEvent('error', {'message': 'è™•ç†å¤±æ•—ï¼Œæœªè¿”å›çµæœ'})
            
        except Exception as e:
            logger.error(f"æµå¼æ™ºèƒ½è·¯ç”±å¤±æ•—: {e}", exc_info=True)
            yield StreamEvent('error', {'message': str(e)})


# å‰µå»ºå…¨å±€å¯¦ä¾‹
qa_orchestrator = QAOrchestrator()
