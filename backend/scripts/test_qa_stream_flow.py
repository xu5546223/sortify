"""
QA æµå¼ç«¯é»æ¸¬è©¦è…³æœ¬ - å¤šè¼ªå°è©±ä¸Šä¸‹æ–‡æ¸¬è©¦

æ¸¬è©¦ç›®æ¨™ï¼š
1. ç¬¬ä¸€è¼ªå°è©±ï¼šå•ã€Œå¹«æˆ‘æ‰¾æ‰€æœ‰çš„ç½°å–®ã€
2. ç¬¬äºŒè¼ªå°è©±ï¼šå•ã€Œç¬¬ä¸€å¼µç½°å–®çš„é‡‘é¡æ˜¯å¤šå°‘ã€ï¼ˆæ¸¬è©¦ä¸Šä¸‹æ–‡ä¿ç•™ï¼‰
3. ç¬¬ä¸‰è¼ªå°è©±ï¼šå•ã€Œå‰›æ‰é‚£äº›ç½°å–®ä¸­ï¼Œæœ‰æ²’æœ‰è¶…é€Ÿçš„ï¼Ÿã€ï¼ˆæ¸¬è©¦ç›¸é—œæ€§è¡°æ¸›ï¼‰
4. ç¬¬å››è¼ªå°è©±ï¼šå•ã€Œå¹«æˆ‘æ‰¾æ°´è²»å¸³å–®ã€ï¼ˆæ¸¬è©¦æ–°æ–‡æª”åŠ å…¥ + èˆŠæ–‡æª”è¡°æ¸›ï¼‰

èª¿ç”¨èˆ‡é›»è…¦ç«¯å®Œå…¨ç›¸åŒçš„æµå¼ API: qa_orchestrator.process_qa_request_intelligent_stream()
è§€å¯Ÿå¤šè¼ªå°è©±ä¹‹é–“çš„ä¸Šä¸‹æ–‡ä¿ç•™æƒ…æ³

ä¸Šä¸‹æ–‡ç®¡ç†èªªæ˜ï¼š
==================
1. æ­·å²å°è©± (messages): ä¿å­˜å•ç­”å°ï¼Œç”¨æ–¼ AI ç†è§£å°è©±è„ˆçµ¡
   - æœ€å¤§ä¿ç•™ 20 æ¢æ¶ˆæ¯ï¼ˆè¶…éè‡ªå‹•ç§»é™¤æœ€èˆŠçš„ï¼‰
2. æ–‡æª”æ±  (cached_document_data): ä¿å­˜æ–‡æª”æ‘˜è¦ï¼Œç”¨æ–¼ AI è­˜åˆ¥å¯ç”¨æ–‡æª”
   - æœ€å¤§ä¿ç•™ 20 å€‹æ–‡æª”ï¼ˆè¶…éæŒ‰å„ªå…ˆç´šç§»é™¤ï¼‰
   - ç›¸é—œæ€§æœƒéš¨æ™‚é–“è¡°æ¸›ï¼ˆæ¯è¼ªæœªå¼•ç”¨ -0.1ï¼‰
   - ä½ç›¸é—œæ€§(<0.35) + 5è¼ªæœªè¨ªå•çš„æ–‡æª”æœƒè¢«æ¸…ç†
3. ä¸Šä¸‹æ–‡ â‰  æ­·å²å°è©±ï¼š
   - æ­·å²å°è©±ï¼šå•é¡Œ + ç­”æ¡ˆ
   - ä¸Šä¸‹æ–‡ï¼šæ­·å²å°è©± + æ–‡æª”æ±  + ç•¶å‰æœç´¢çµæœ
"""
import asyncio
import sys
import os
import json
from datetime import datetime
from uuid import UUID

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from motor.motor_asyncio import AsyncIOMotorClient
from app.core.config import settings
from app.services.vector.vector_db_service import vector_db_service
from app.services.qa_orchestrator import qa_orchestrator
from app.models.vector_models import AIQARequest
from app.crud import crud_conversations


def print_separator(title: str, char: str = "="):
    """æ‰“å°åˆ†éš”ç·š"""
    print(f"\n{char * 80}")
    print(f"ğŸ“Š {title}")
    print(f"{char * 80}")


async def get_conversation_state(db, conversation_id: str, user_uuid) -> dict:
    """ç²å–å°è©±çš„å®Œæ•´ç‹€æ…‹ï¼ˆæ­·å²å°è©± + æ–‡æª”æ± ï¼‰"""
    
    # 1. ç²å–å°è©±æ­·å²
    conversation = await crud_conversations.get_conversation(
        db=db,
        conversation_id=UUID(conversation_id),
        user_id=user_uuid
    )
    
    message_count = len(conversation.messages) if conversation and conversation.messages else 0
    
    # 2. ç²å–æ–‡æª”æ± 
    cached_doc_ids, cached_doc_data = await crud_conversations.get_cached_documents(
        db=db,
        conversation_id=UUID(conversation_id),
        user_id=user_uuid
    )
    
    doc_pool_size = len(cached_doc_data) if cached_doc_data else 0
    
    # 3. æ”¶é›†æ–‡æª”ç›¸é—œæ€§ä¿¡æ¯
    doc_relevance_info = []
    if cached_doc_data:
        for doc_id, doc_info in cached_doc_data.items():
            if isinstance(doc_info, dict):
                doc_relevance_info.append({
                    'filename': doc_info.get('filename', 'Unknown')[:40],
                    'relevance_score': doc_info.get('relevance_score', 0),
                    'access_count': doc_info.get('access_count', 0),
                    'last_accessed_round': doc_info.get('last_accessed_round', 0),
                    'first_mentioned_round': doc_info.get('first_mentioned_round', 0)
                })
    
    return {
        'message_count': message_count,
        'doc_pool_size': doc_pool_size,
        'doc_relevance_info': doc_relevance_info
    }


async def run_single_qa_round(
    db,
    user_id: str,
    question: str,
    conversation_id: str,
    round_num: int,
    workflow_action: str = 'approve_search',
    simulate_real_flow: bool = True  # æ˜¯å¦æ¨¡æ“¬çœŸå¯¦çš„å…©éšæ®µæµç¨‹
) -> dict:
    """åŸ·è¡Œå–®è¼ª QA å°è©±ä¸¦è¿”å›çµæœ"""
    
    print_separator(f"ç¬¬ {round_num} è¼ªå°è©±", "=")
    print(f"\nğŸ“ å•é¡Œ: {question}")
    print(f"ğŸ’¬ å°è©± ID: {conversation_id}")
    print(f"ğŸ”§ é æœŸæ‰¹å‡†å‹•ä½œ: {workflow_action}")
    print(f"ğŸ”„ æ¨¡æ“¬çœŸå¯¦æµç¨‹: {simulate_real_flow}")
    print("-" * 80)
    
    start_time = datetime.now()
    event_count = 0
    final_answer = None
    llm_contexts = []
    document_pool = []
    cached_doc_ids = []
    
    try:
        # ========== éšæ®µ 1: é¦–æ¬¡è«‹æ±‚ï¼ˆä¸å¸¶ workflow_actionï¼‰==========
        if simulate_real_flow:
            print("\n   ğŸ”¹ éšæ®µ 1: é¦–æ¬¡è«‹æ±‚ï¼ˆç­‰å¾…æ‰¹å‡†ï¼‰")
            
            qa_request_phase1 = AIQARequest(
                question=question,
                context_limit=5,
                use_semantic_search=True,
                model_preference=None,
                query_rewrite_count=3,
                similarity_threshold=0.3,
                workflow_action=None,  # é¦–æ¬¡è«‹æ±‚ä¸å¸¶ workflow_action
                conversation_id=conversation_id
            )
            
            approval_received = False
            approval_data = None
            
            async for event in qa_orchestrator.process_qa_request_intelligent_stream(
                db=db,
                request=qa_request_phase1,
                user_id=user_id,
                request_id=f"test_round_{round_num}_phase1"
            ):
                event_count += 1
                event_type = event.type
                event_data = event.data
                
                if event_type == 'progress':
                    stage = event_data.get('stage', '')
                    message = event_data.get('message', '')
                    print(f"   ğŸ“ [{stage}] {message}")
                
                elif event_type == 'approval_needed':
                    approval_received = True
                    approval_data = event_data
                    pending = event_data.get('pending_approval', '')
                    print(f"\n   â¸ï¸ æ”¶åˆ°æ‰¹å‡†è«‹æ±‚: {pending}")
                
                elif event_type == 'complete':
                    # æŸäº›æ„åœ–ï¼ˆå¦‚ GREETINGï¼‰ä¸éœ€è¦æ‰¹å‡†ï¼Œç›´æ¥å®Œæˆ
                    final_answer = event_data.get('answer', '')
                    print(f"\n   âœ… ç›´æ¥å®Œæˆï¼ˆç„¡éœ€æ‰¹å‡†ï¼‰: {len(final_answer)} å­—")
                
                elif event_type == 'error':
                    print(f"   âŒ éŒ¯èª¤: {event_data.get('message', '')}")
            
            # å¦‚æœæ”¶åˆ°æ‰¹å‡†è«‹æ±‚ï¼Œé€²å…¥éšæ®µ 2
            if approval_received:
                print(f"\n   ğŸ”¹ éšæ®µ 2: æ‰¹å‡†è«‹æ±‚ï¼ˆ{workflow_action}ï¼‰")
                await asyncio.sleep(0.1)  # æ¨¡æ“¬ç”¨æˆ¶æ€è€ƒæ™‚é–“
            elif final_answer:
                # å·²ç¶“å®Œæˆï¼Œä¸éœ€è¦éšæ®µ 2
                end_time = datetime.now()
                duration = (end_time - start_time).total_seconds()
                print(f"\nâ±ï¸ è€—æ™‚: {duration:.2f} ç§’ | äº‹ä»¶æ•¸: {event_count}")
                return {
                    "answer": final_answer,
                    "llm_contexts": llm_contexts,
                    "document_pool": document_pool,
                    "cached_doc_ids": cached_doc_ids,
                    "duration": duration
                }
        
        # ========== éšæ®µ 2: æ‰¹å‡†è«‹æ±‚ï¼ˆå¸¶ workflow_actionï¼‰==========
        qa_request_phase2 = AIQARequest(
            question=question,
            context_limit=5,
            use_semantic_search=True,
            model_preference=None,
            query_rewrite_count=3,
            similarity_threshold=0.3,
            workflow_action=workflow_action,  # å¸¶ä¸Šæ‰¹å‡†å‹•ä½œ
            conversation_id=conversation_id
        )
        
        async for event in qa_orchestrator.process_qa_request_intelligent_stream(
            db=db,
            request=qa_request_phase2,
            user_id=user_id,
            request_id=f"test_round_{round_num}_phase2"
        ):
            event_count += 1
            event_type = event.type
            event_data = event.data
            
            if event_type == 'progress':
                stage = event_data.get('stage', '')
                message = event_data.get('message', '')
                print(f"   ğŸ“ [{stage}] {message}")
            
            elif event_type == 'chunk':
                # æµå¼è¼¸å‡ºï¼Œä¸æ‰“å°æ¯å€‹ chunk
                pass
            
            elif event_type == 'complete':
                final_answer = event_data.get('answer', '')
                print(f"\n   âœ… æ”¶åˆ°å®Œæ•´ç­”æ¡ˆ ({len(final_answer)} å­—)")
            
            elif event_type == 'metadata':
                if 'llm_context_documents' in event_data:
                    llm_contexts = event_data['llm_context_documents']
                if 'document_pool' in event_data:
                    document_pool = event_data['document_pool']
                if 'cached_document_ids' in event_data:
                    cached_doc_ids = event_data['cached_document_ids']
            
            elif event_type == 'error':
                print(f"   âŒ éŒ¯èª¤: {event_data.get('message', '')}")
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print(f"\nâ±ï¸ è€—æ™‚: {duration:.2f} ç§’ | äº‹ä»¶æ•¸: {event_count}")
        
        return {
            "answer": final_answer,
            "llm_contexts": llm_contexts,
            "document_pool": document_pool,
            "cached_doc_ids": cached_doc_ids,
            "duration": duration
        }
        
    except Exception as e:
        print(f"\nâŒ è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None


async def test_qa_stream_flow():
    """æ¸¬è©¦å¤šè¼ªå°è©±çš„ä¸Šä¸‹æ–‡ä¿ç•™æƒ…æ³"""
    
    print("=" * 80)
    print("ğŸ” å¤šè¼ªå°è©±ä¸Šä¸‹æ–‡æ¸¬è©¦ï¼ˆå››è¼ªï¼‰")
    print("ğŸ“Œ æ¸¬è©¦ç›®æ¨™ï¼šæ–‡æª”æ± åŠ è¼‰ã€ä¸Šä¸‹æ–‡ç®¡ç†ã€æ–‡æª”é¸ç”¨ã€ç›¸é—œæ€§è¡°æ¸›")
    print("=" * 80)
    
    # é€£æ¥ MongoDB
    client = AsyncIOMotorClient(
        settings.MONGODB_URL,
        uuidRepresentation='standard'
    )
    db = client[settings.DB_NAME]
    
    # åˆå§‹åŒ–å‘é‡è³‡æ–™åº«
    vector_db_service.create_collection(768)
    
    # ç²å–æ¸¬è©¦ç”¨æˆ¶
    import uuid as uuid_module
    sample_doc = await db.documents.find_one({})
    if not sample_doc:
        print("âŒ è³‡æ–™åº«ä¸­æ²’æœ‰æ–‡æª”")
        return
    
    owner_id = sample_doc.get("owner_id")
    if isinstance(owner_id, uuid_module.UUID):
        user_id = str(owner_id)
        user_uuid = owner_id
    elif isinstance(owner_id, bytes):
        user_uuid = uuid_module.UUID(bytes=owner_id)
        user_id = str(user_uuid)
    else:
        user_uuid = uuid_module.UUID(str(owner_id))
        user_id = str(owner_id)
    
    print(f"\nğŸ‘¤ ä½¿ç”¨ç”¨æˆ¶ ID: {user_id}")
    
    # è¼‰å…¥é…ç½®
    from app.models.context_config import context_config
    
    # ========== å‰µå»ºæ–°å°è©± ==========
    print_separator("å‰µå»ºæ–°å°è©±")
    
    first_question = "å¹«æˆ‘æ‰¾æ‰€æœ‰çš„ç½°å–®"
    conversation = await crud_conversations.create_conversation(
        db=db,
        user_id=user_uuid,
        first_question=first_question
    )
    conversation_id = str(conversation.id)
    print(f"âœ… å‰µå»ºå°è©±æˆåŠŸ: {conversation_id}")
    
    # ========== æ”¶é›†æ¯è¼ªæ•¸æ“š ==========
    round_data = []  # æ”¶é›†æ¯è¼ªçš„ç‹€æ…‹æ•¸æ“š
    
    # å®šç¾©å››è¼ªå°è©±
    # æ³¨æ„ï¼šaction éœ€è¦æ ¹æ“š AI åˆ†é¡çµæœä¾†è¨­å®š
    # - approve_search: ç”¨æ–¼ DOCUMENT_SEARCH æ„åœ–
    # - approve_detail_query: ç”¨æ–¼ DOCUMENT_DETAIL_QUERY æ„åœ–
    rounds = [
        {"question": "å¹«æˆ‘æ‰¾æ‰€æœ‰çš„ç½°å–®", "action": "approve_search", "desc": "æœç´¢ç½°å–®"},
        {"question": "ç¬¬ä¸€å¼µç½°å–®çš„é‡‘é¡æ˜¯å¤šå°‘", "action": "approve_detail_query", "desc": "æŸ¥è©¢è©³æƒ…"},
        {"question": "å‰›æ‰é‚£äº›ç½°å–®ä¸­ï¼Œæœ‰æ²’æœ‰è¶…é€Ÿçš„ï¼Ÿå¦‚æœæœ‰ï¼Œæ˜¯å“ªä¸€å¼µï¼Ÿ", "action": "approve_detail_query", "desc": "è¿½å•è¶…é€Ÿï¼ˆè©³ç´°æŸ¥è©¢ï¼‰"},
        {"question": "å¹«æˆ‘æ‰¾æ°´è²»å¸³å–®", "action": "approve_search", "desc": "æœç´¢æ°´è²»ï¼ˆæ–°ä¸»é¡Œï¼‰"},
    ]
    
    # ========== åŸ·è¡Œå››è¼ªå°è©± ==========
    for i, round_info in enumerate(rounds, 1):
        print_separator(f"ç¬¬ {i} è¼ªå°è©± - {round_info['desc']}", "=" if i == 1 else "-")
        
        # ç²å–å°è©±å‰ç‹€æ…‹
        state_before = await get_conversation_state(db, conversation_id, user_uuid)
        
        # åŸ·è¡Œå°è©±
        result = await run_single_qa_round(
            db=db,
            user_id=user_id,
            question=round_info['question'],
            conversation_id=conversation_id,
            round_num=i,
            workflow_action=round_info['action']
        )
        
        # ç­‰å¾…æ•¸æ“šä¿å­˜
        await asyncio.sleep(0.5)
        
        # ç²å–å°è©±å¾Œç‹€æ…‹
        state_after = await get_conversation_state(db, conversation_id, user_uuid)
        
        # ç°¡è¦é¡¯ç¤ºç­”æ¡ˆ
        if result and result['answer']:
            print(f"\nğŸ“ AI ç­”æ¡ˆï¼ˆå‰ 200 å­—ï¼‰:")
            print(f"   {result['answer'][:200]}...")
        
        # æ”¶é›†æœ¬è¼ªæ•¸æ“š
        round_data.append({
            'round': i,
            'question': round_info['question'],
            'desc': round_info['desc'],
            'state_before': state_before,
            'state_after': state_after,
            'answer': result['answer'] if result else None
        })
    
    # ========== æœ€çµ‚çµ±ä¸€è¼¸å‡º ==========
    print("\n")
    print("â–ˆ" * 80)
    print("â–ˆ" + " " * 30 + "ğŸ“Š æ¸¬è©¦çµæœç¸½è¦½" + " " * 31 + "â–ˆ")
    print("â–ˆ" * 80)
    
    # 1. é…ç½®ä¿¡æ¯
    print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ğŸ“‹ ä¸Šä¸‹æ–‡ç®¡ç†é…ç½®                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MAX_MESSAGES_PER_CONVERSATION: {context_config.MAX_MESSAGES_PER_CONVERSATION:<5}  â”‚  æœ€å¤§æ­·å²æ¶ˆæ¯æ•¸              â”‚
â”‚  DEFAULT_HISTORY_LIMIT:         {context_config.DEFAULT_HISTORY_LIMIT:<5}  â”‚  é»˜èªè¼‰å…¥æ­·å²æ•¸              â”‚
â”‚  MAX_DOCUMENT_POOL_SIZE:        {context_config.MAX_DOCUMENT_POOL_SIZE:<5}  â”‚  æ–‡æª”æ± æœ€å¤§å¤§å°              â”‚
â”‚  MIN_RELEVANCE_SCORE:           {context_config.MIN_RELEVANCE_SCORE:<5}  â”‚  æœ€ä½ç›¸é—œæ€§é–¾å€¼              â”‚
â”‚  MAX_IDLE_ROUNDS:               {context_config.MAX_IDLE_ROUNDS:<5}  â”‚  æœ€å¤§é–’ç½®è¼ªæ¬¡                â”‚
â”‚  RELEVANCE_DECAY_RATE:          {context_config.RELEVANCE_DECAY_RATE:<5}  â”‚  æ¯è¼ªè¡°æ¸›ç‡                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")
    
    # 2. æ¯è¼ªå°è©±ç‹€æ…‹è®ŠåŒ–
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ğŸ“ˆ æ¯è¼ªå°è©±ç‹€æ…‹è®ŠåŒ–                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤""")
    
    for rd in round_data:
        before = rd['state_before']
        after = rd['state_after']
        print(f"""
â”‚  ã€ç¬¬ {rd['round']} è¼ªã€‘{rd['desc']:<20}                                      â”‚
â”‚  â”œâ”€â”€ å•é¡Œ: {rd['question'][:50]:<50}â”‚
â”‚  â”œâ”€â”€ æ¶ˆæ¯æ•¸: {before['message_count']} â†’ {after['message_count']}                                                   â”‚
â”‚  â””â”€â”€ æ–‡æª”æ± : {before['doc_pool_size']} â†’ {after['doc_pool_size']} å€‹æ–‡æª”                                            â”‚""")
    
    print("""â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜""")
    
    # 3. æœ€çµ‚æ–‡æª”æ± ç‹€æ…‹ï¼ˆç›¸é—œæ€§è©³æƒ…ï¼‰
    final_state = round_data[-1]['state_after']
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ“ æœ€çµ‚æ–‡æª”æ± ç‹€æ…‹ï¼ˆç›¸é—œæ€§è©³æƒ…ï¼‰                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ–‡ä»¶å                              â”‚ ç›¸é—œæ€§ â”‚ è¨ªå•æ¬¡æ•¸ â”‚ é¦–æ¬¡è¼ªæ¬¡ â”‚ æœ€å¾Œè¼ªæ¬¡â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤""")
    
    for doc in final_state['doc_relevance_info']:
        filename = doc['filename'][:36].ljust(36)
        relevance = f"{doc['relevance_score']:.2f}".center(6)
        access = str(doc['access_count']).center(8)
        first_round = str(doc['first_mentioned_round']).center(8)
        last_round = str(doc['last_accessed_round']).center(7)
        print(f"â”‚  {filename} â”‚ {relevance} â”‚ {access} â”‚ {first_round} â”‚ {last_round} â”‚")
    
    print("""â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜""")
    
    # 4. é©—è­‰çµæœ
    final_msg_count = final_state['message_count']
    final_doc_count = final_state['doc_pool_size']
    
    # æª¢æŸ¥æ˜¯å¦æœ‰è¡°æ¸›ç™¼ç”Ÿ
    has_decay = any(doc['relevance_score'] < 1.0 for doc in final_state['doc_relevance_info'])
    
    print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              âœ… é©—è­‰çµæœ                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1ï¸âƒ£  æ­·å²å°è©±ç®¡ç†                                                           â”‚
â”‚      â”œâ”€â”€ ç•¶å‰æ¶ˆæ¯æ•¸: {final_msg_count}                                                     â”‚
â”‚      â”œâ”€â”€ æœ€å¤§é™åˆ¶: {context_config.MAX_MESSAGES_PER_CONVERSATION}                                                      â”‚
â”‚      â””â”€â”€ ç‹€æ…‹: {'âœ“ æ­£å¸¸' if final_msg_count <= context_config.MAX_MESSAGES_PER_CONVERSATION else 'âš ï¸ è¶…å‡ºé™åˆ¶'}                                                      â”‚
â”‚                                                                             â”‚
â”‚  2ï¸âƒ£  æ–‡æª”æ± ç®¡ç†                                                             â”‚
â”‚      â”œâ”€â”€ ç•¶å‰æ–‡æª”æ•¸: {final_doc_count}                                                     â”‚
â”‚      â”œâ”€â”€ æœ€å¤§é™åˆ¶: {context_config.MAX_DOCUMENT_POOL_SIZE}                                                      â”‚
â”‚      â””â”€â”€ ç‹€æ…‹: {'âœ“ æ­£å¸¸' if final_doc_count <= context_config.MAX_DOCUMENT_POOL_SIZE else 'âš ï¸ è¶…å‡ºé™åˆ¶'}                                                      â”‚
â”‚                                                                             â”‚
â”‚  3ï¸âƒ£  ç›¸é—œæ€§è¡°æ¸›                                                             â”‚
â”‚      â””â”€â”€ ç‹€æ…‹: {'âœ“ æœ‰æ–‡æª”ç™¼ç”Ÿè¡°æ¸›' if has_decay else 'âš ï¸ æœªè§€å¯Ÿåˆ°è¡°æ¸›ï¼ˆå¯èƒ½éƒ½è¢«å¼•ç”¨ï¼‰'}                                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")
    
    # 5. æ©Ÿåˆ¶èªªæ˜
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å¤šè¼ªå°è©±ä¸Šä¸‹æ–‡ç®¡ç†æ©Ÿåˆ¶                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€æœƒä¿ç•™åˆ°ä¸‹ä¸€è¼ªçš„æ•¸æ“šã€‘                                                    â”‚
â”‚  â”œâ”€â”€ æ­·å²å°è©± (messages)                                                    â”‚
â”‚  â”‚   â€¢ å•é¡Œ + ç­”æ¡ˆï¼Œè®“ AI ç†è§£å°è©±è„ˆçµ¡                                      â”‚
â”‚  â”‚   â€¢ âš¡ æœ€å¤§ä¿ç•™ 20 æ¢ï¼ˆè¶…éè‡ªå‹•ç§»é™¤æœ€èˆŠçš„ï¼‰                               â”‚
â”‚  â”‚                                                                          â”‚
â”‚  â””â”€â”€ æ–‡æª”æ±  (cached_document_data)                                          â”‚
â”‚      â€¢ æ–‡æª” ID + æ–‡ä»¶å + æ‘˜è¦ + ç›¸é—œæ€§åˆ†æ•¸                                 â”‚
â”‚      â€¢ âš¡ æœ€å¤§ä¿ç•™ 20 å€‹ï¼ˆè¶…éæŒ‰å„ªå…ˆç´šç§»é™¤ï¼‰                                 â”‚
â”‚      â€¢ âš¡ æœªè¢«å¼•ç”¨çš„æ–‡æª”æ¯è¼ªè¡°æ¸› 0.1                                         â”‚
â”‚      â€¢ âš¡ ç›¸é—œæ€§ < 0.35 ä¸” 5 è¼ªæœªè¨ªå• â†’ è‡ªå‹•æ¸…ç†                             â”‚
â”‚                                                                             â”‚
â”‚  ã€å„ªå…ˆç´šè¨ˆç®—ã€‘                                                              â”‚
â”‚  priority = relevance_score Ã— 0.7 + recency_score Ã— 0.3                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")
    
    # é—œé–‰é€£æ¥
    client.close()
    
    print("\n" + "=" * 80)
    print("âœ… å››è¼ªå°è©±æ¸¬è©¦å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(test_qa_stream_flow())
