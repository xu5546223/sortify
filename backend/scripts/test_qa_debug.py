"""
QA æµç¨‹èª¿è©¦è…³æœ¬

æ¸¬è©¦å•é¡Œ: å¹«æˆ‘æ‰¾æ‰€æœ‰çš„ç½°å–®
é¡¯ç¤ºå®Œæ•´çš„æœç´¢æµç¨‹å’Œ AI åŸå§‹çµæœ
"""
import asyncio
import sys
import os
import json
from datetime import datetime

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from motor.motor_asyncio import AsyncIOMotorClient
from app.core.config import settings
from app.services.vector.embedding_service import embedding_service
from app.services.vector.vector_db_service import vector_db_service
from app.services.vector.enhanced_search_service import enhanced_search_service


async def test_vector_search_debug():
    """æ¸¬è©¦å‘é‡æœç´¢ä¸¦é¡¯ç¤ºè©³ç´°çµæœ"""
    
    print("=" * 80)
    print("ğŸ” QA æµç¨‹èª¿è©¦æ¸¬è©¦")
    print("=" * 80)
    
    # æ¸¬è©¦å•é¡Œ
    test_query = "å¹«æˆ‘æ‰¾æ‰€æœ‰çš„ç½°å–®"
    print(f"\nğŸ“ æ¸¬è©¦å•é¡Œ: {test_query}")
    print("-" * 80)
    
    # é€£æ¥ MongoDB (ä½¿ç”¨æ­£ç¢ºçš„ UUID è¡¨ç¤ºæ–¹å¼)
    client = AsyncIOMotorClient(
        settings.MONGODB_URL,
        uuidRepresentation='standard'  # é‡è¦ï¼šèˆ‡æ‡‰ç”¨ç¨‹å¼ä¿æŒä¸€è‡´
    )
    db = client[settings.DB_NAME]
    
    # åˆå§‹åŒ–å‘é‡è³‡æ–™åº«é›†åˆ
    vector_db_service.create_collection(768)  # 768 ç¶­åº¦ for multilingual-e5-base
    
    # ç²å–ä¸€å€‹æ¸¬è©¦ç”¨æˆ¶ ID (å¾è³‡æ–™åº«ä¸­ç²å–ç¬¬ä¸€å€‹ç”¨æˆ¶)
    sample_doc = await db.documents.find_one({})
    if not sample_doc:
        print("âŒ è³‡æ–™åº«ä¸­æ²’æœ‰æ–‡æª”")
        return
    
    # æ­£ç¢ºè½‰æ› UUID
    import uuid as uuid_module
    owner_id = sample_doc.get("owner_id")
    if isinstance(owner_id, uuid_module.UUID):
        user_id = str(owner_id)
    elif isinstance(owner_id, bytes):
        user_id = str(uuid_module.UUID(bytes=owner_id))
    else:
        user_id = str(owner_id)
    print(f"ğŸ‘¤ ä½¿ç”¨ç”¨æˆ¶ ID: {user_id}")
    
    # ========== Step 1: å‘é‡åŒ–æŸ¥è©¢ ==========
    print("\n" + "=" * 80)
    print("ğŸ“Š Step 1: å‘é‡åŒ–æŸ¥è©¢")
    print("=" * 80)
    
    query_vector = embedding_service.encode_text(test_query)
    print(f"âœ… æŸ¥è©¢å‘é‡ç¶­åº¦: {len(query_vector)}")
    
    # ========== Step 2: åŸ·è¡Œå‘é‡æœç´¢ (å‚³çµ±å–®éšæ®µ) ==========
    print("\n" + "=" * 80)
    print("ğŸ“Š Step 2: å‚³çµ±å–®éšæ®µæœç´¢ (æ‘˜è¦ + chunk)")
    print("=" * 80)
    
    # æœç´¢æ‘˜è¦å‘é‡
    summary_results = vector_db_service.search_similar_vectors(
        query_vector=query_vector,
        top_k=5,
        owner_id_filter=user_id,
        similarity_threshold=0.3,
        metadata_filter={"type": "summary"}
    )
    
    print(f"\nğŸ“„ æ‘˜è¦å‘é‡æœç´¢çµæœ: {len(summary_results)} å€‹")
    for i, result in enumerate(summary_results, 1):
        print(f"\n  --- æ‘˜è¦çµæœ {i} ---")
        print(f"  ğŸ“ Document ID: {result.document_id}")
        print(f"  ğŸ“ˆ ç›¸ä¼¼åº¦: {result.similarity_score:.4f}")
        print(f"  ğŸ“ summary_text (å‰ 300 å­—):")
        print(f"     {result.summary_text[:300]}..." if len(result.summary_text) > 300 else f"     {result.summary_text}")
        print(f"  ğŸ·ï¸ Metadata:")
        for key, value in (result.metadata or {}).items():
            if value:
                print(f"     - {key}: {value}")
    
    # æœç´¢ chunk å‘é‡
    chunk_results = vector_db_service.search_similar_vectors(
        query_vector=query_vector,
        top_k=5,
        owner_id_filter=user_id,
        similarity_threshold=0.3,
        metadata_filter={"type": "chunk"}
    )
    
    print(f"\nğŸ“„ Chunk å‘é‡æœç´¢çµæœ: {len(chunk_results)} å€‹")
    for i, result in enumerate(chunk_results, 1):
        print(f"\n  --- Chunk çµæœ {i} ---")
        print(f"  ğŸ“ Document ID: {result.document_id}")
        print(f"  ğŸ“ˆ ç›¸ä¼¼åº¦: {result.similarity_score:.4f}")
        print(f"  ğŸ“ è¡Œè™Ÿç¯„åœ: {result.start_line} - {result.end_line}")
        print(f"  ğŸ“¦ Chunk é¡å‹: {result.chunk_type}")
        print(f"  ğŸ“ summary_text (chunk_text, å‰ 500 å­—):")
        text_preview = result.summary_text[:500] + "..." if len(result.summary_text) > 500 else result.summary_text
        print(f"     {text_preview}")
        print(f"  ğŸ·ï¸ Metadata:")
        for key, value in (result.metadata or {}).items():
            if value:
                print(f"     - {key}: {value}")
    
    # ========== Step 3: åŸ·è¡Œ RRF èåˆæœç´¢ ==========
    print("\n" + "=" * 80)
    print("ğŸ“Š Step 3: RRF èåˆæœç´¢")
    print("=" * 80)
    
    rrf_results = await enhanced_search_service.two_stage_hybrid_search(
        db=db,
        query=test_query,
        user_id=user_id,
        search_type="rrf_fusion",
        stage2_top_k=5,
        similarity_threshold=0.3
    )
    
    print(f"\nğŸ“„ RRF èåˆæœç´¢çµæœ: {len(rrf_results)} å€‹")
    for i, result in enumerate(rrf_results, 1):
        print(f"\n  --- RRF çµæœ {i} ---")
        print(f"  ğŸ“ Document ID: {result.document_id}")
        print(f"  ğŸ“ˆ RRF åˆ†æ•¸: {result.similarity_score:.4f}")
        print(f"  ğŸ“ è¡Œè™Ÿç¯„åœ: {result.start_line} - {result.end_line}")
        print(f"  ğŸ“¦ Chunk é¡å‹: {result.chunk_type}")
        print(f"  ğŸ“ summary_text (å‰ 500 å­—):")
        text_preview = result.summary_text[:500] + "..." if len(result.summary_text) > 500 else result.summary_text
        print(f"     {text_preview}")
        
        # é¡¯ç¤º RRF è©³ç´°ä¿¡æ¯
        if result.metadata and result.metadata.get("rrf_details"):
            rrf_details = result.metadata.get("rrf_details", {})
            print(f"  ğŸ¯ RRF è©³æƒ…:")
            print(f"     - æœ€çµ‚ RRF åˆ†æ•¸: {rrf_details.get('final_rrf_score', 'N/A')}")
            for comp in rrf_details.get("components", []):
                print(f"     - {comp.get('type', 'unknown')}: rank={comp.get('rank', 'N/A')}, contribution={comp.get('contribution', 'N/A'):.4f}")
    
    # ========== Step 4: ç²å–å®Œæ•´æ–‡æª” (æ¨¡æ“¬ QA æµç¨‹) ==========
    print("\n" + "=" * 80)
    print("ğŸ“Š Step 4: ç²å–å®Œæ•´æ–‡æª” (æ¨¡æ“¬ QA æµç¨‹)")
    print("=" * 80)
    
    if rrf_results:
        from app.crud.crud_documents import get_documents_by_ids
        document_ids = [result.document_id for result in rrf_results]
        documents = await get_documents_by_ids(db, document_ids)
        
        print(f"\nğŸ“„ ç²å–åˆ° {len(documents)} å€‹å®Œæ•´æ–‡æª”")
        for i, doc in enumerate(documents, 1):
            print(f"\n  --- æ–‡æª” {i} ---")
            print(f"  ğŸ“ ID: {doc.id}")
            print(f"  ğŸ“ æ–‡ä»¶å: {doc.filename}")
            print(f"  ğŸ“‚ æ–‡ä»¶é¡å‹: {doc.file_type}")
            
            # ç²å– AI åˆ†æçš„æ‘˜è¦ (é€™æ˜¯ç›®å‰ QA æµç¨‹ä½¿ç”¨çš„)
            ai_summary = None
            if hasattr(doc, 'analysis') and doc.analysis:
                if hasattr(doc.analysis, 'ai_analysis_output') and isinstance(doc.analysis.ai_analysis_output, dict):
                    key_info = doc.analysis.ai_analysis_output.get("key_information", {})
                    if isinstance(key_info, dict):
                        ai_summary = key_info.get("content_summary", "")
            
            print(f"  ğŸ“ AI æ‘˜è¦ (content_summary, ç›®å‰ QA ä½¿ç”¨çš„):")
            if ai_summary:
                preview = ai_summary[:300] + "..." if len(ai_summary) > 300 else ai_summary
                print(f"     {preview}")
            else:
                print(f"     (ç„¡)")
    
    # ========== Step 5: å°æ¯”åˆ†æ ==========
    print("\n" + "=" * 80)
    print("ğŸ“Š Step 5: å°æ¯”åˆ†æ - æœç´¢çµæœ vs ç›®å‰ QA ä½¿ç”¨çš„å…§å®¹")
    print("=" * 80)
    
    print("\nâš ï¸ é—œéµç™¼ç¾:")
    print("-" * 40)
    print("1. å‘é‡æœç´¢è¿”å›çš„ summary_text åŒ…å«:")
    print("   - å°æ–¼æ‘˜è¦å‘é‡: æ–‡ä»¶å+æ‘˜è¦+é—œéµè©çš„çµ„åˆ")
    print("   - å°æ–¼ chunk å‘é‡: åŸå§‹æ–‡æœ¬å¡Š æˆ– [Summary]+[Content] æ··åˆå…§å®¹")
    print("")
    print("2. ç›®å‰ QA æµç¨‹:")
    print("   - ä¸Ÿæ£„äº†æœç´¢è¿”å›çš„ summary_text (chunk å…§å®¹)")
    print("   - é‡æ–°å¾ MongoDB ç²å–æ–‡æª”")
    print("   - ä½¿ç”¨æ–‡æª”ç´šçš„ content_summary")
    print("")
    print("3. å»ºè­°å„ªåŒ–:")
    print("   - å°‡æœç´¢åˆ°çš„ chunk å…§å®¹å‚³éçµ¦ AI")
    print("   - åˆ©ç”¨è¡Œè™Ÿè³‡è¨Š (start_line, end_line) æä¾›ç²¾ç¢ºå¼•ç”¨")
    
    # é—œé–‰é€£æ¥
    client.close()
    
    print("\n" + "=" * 80)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(test_vector_search_debug())
