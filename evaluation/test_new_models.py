"""æ¸¬è©¦æ–°çš„ Embedding æ¨¡å‹å’Œ Reranker"""
import sys
import os

# æ·»åŠ  backend è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))

def test_embedding_model():
    """æ¸¬è©¦æ–°çš„ Embedding æ¨¡å‹"""
    print("=" * 60)
    print("æ¸¬è©¦ Embedding æ¨¡å‹: intfloat/multilingual-e5-base")
    print("=" * 60)
    
    from sentence_transformers import SentenceTransformer
    import torch
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è¨­å‚™: {device}")
    
    print("æ­£åœ¨è¼‰å…¥æ¨¡å‹...")
    model = SentenceTransformer("intfloat/multilingual-e5-base", device=device)
    
    # æ¸¬è©¦å¤šèªè¨€
    test_texts = [
        "query: é€™å¼µç™¼ç¥¨çš„ç¸½é‡‘é¡æ˜¯å¤šå°‘ï¼Ÿ",  # ä¸­æ–‡
        "query: What is the total amount of this invoice?",  # è‹±æ–‡
        "query: ã“ã®è«‹æ±‚æ›¸ã®åˆè¨ˆé‡‘é¡ã¯ã„ãã‚‰ã§ã™ã‹ï¼Ÿ",  # æ—¥æ–‡
    ]
    
    print("\næ¸¬è©¦å‘é‡åŒ–:")
    for text in test_texts:
        embedding = model.encode(text)
        print(f"  {text[:40]}... -> ç¶­åº¦: {len(embedding)}")
    
    # æ¸¬è©¦ç›¸ä¼¼åº¦
    print("\næ¸¬è©¦ç›¸ä¼¼åº¦è¨ˆç®—:")
    query = "query: ç™¼ç¥¨é‡‘é¡"
    docs = [
        "passage: æœ¬ç™¼ç¥¨ç¸½é‡‘é¡ç‚º NT$1,500",
        "passage: ä»Šå¤©å¤©æ°£å¾ˆå¥½",
        "passage: ç§Ÿè³ƒå¥‘ç´„çš„ç§Ÿé‡‘æ˜¯æ¯æœˆ 10,000 å…ƒ",
    ]
    
    query_emb = model.encode(query)
    doc_embs = model.encode(docs)
    
    from sentence_transformers.util import cos_sim
    similarities = cos_sim(query_emb, doc_embs)[0]
    
    for doc, sim in zip(docs, similarities):
        print(f"  {doc[:40]}... -> ç›¸ä¼¼åº¦: {sim:.4f}")
    
    print("\nâœ… Embedding æ¨¡å‹æ¸¬è©¦é€šéï¼")
    return True

def test_reranker_model():
    """æ¸¬è©¦ Cross-Encoder Reranker"""
    print("\n" + "=" * 60)
    print("æ¸¬è©¦ Reranker æ¨¡å‹: BAAI/bge-reranker-v2-m3")
    print("=" * 60)
    
    from sentence_transformers import CrossEncoder
    import torch
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨è¨­å‚™: {device}")
    
    print("æ­£åœ¨è¼‰å…¥æ¨¡å‹...")
    model = CrossEncoder("BAAI/bge-reranker-v2-m3", max_length=512, device=device)
    
    # æ¸¬è©¦é‡æ’åº
    query = "é€™å¼µç™¼ç¥¨çš„ç¸½é‡‘é¡æ˜¯å¤šå°‘ï¼Ÿ"
    passages = [
        "æœ¬ç™¼ç¥¨ç¸½é‡‘é¡ç‚º NT$1,500ï¼Œä»˜æ¬¾æ–¹å¼ç‚ºä¿¡ç”¨å¡ã€‚",
        "ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œé©åˆå‡ºé–€æ•£æ­¥ã€‚",
        "ç§Ÿè³ƒå¥‘ç´„è¦å®šæ¯æœˆç§Ÿé‡‘ç‚º 10,000 å…ƒã€‚",
        "ç™¼ç¥¨è™Ÿç¢¼ï¼šAB-12345678ï¼Œæ—¥æœŸï¼š2024/01/15",
    ]
    
    print(f"\næŸ¥è©¢: {query}")
    print("\nåŸå§‹æ’åº:")
    for i, p in enumerate(passages):
        print(f"  {i+1}. {p[:50]}...")
    
    # è¨ˆç®— Cross-Encoder åˆ†æ•¸
    pairs = [[query, p] for p in passages]
    scores = model.predict(pairs)
    
    # æŒ‰åˆ†æ•¸æ’åº
    scored_passages = list(zip(passages, scores))
    scored_passages.sort(key=lambda x: x[1], reverse=True)
    
    print("\né‡æ’åºå¾Œ:")
    for i, (p, score) in enumerate(scored_passages):
        print(f"  {i+1}. [åˆ†æ•¸: {score:.4f}] {p[:50]}...")
    
    print("\nâœ… Reranker æ¨¡å‹æ¸¬è©¦é€šéï¼")
    return True

def test_memory_usage():
    """æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("è¨˜æ†¶é«”ä½¿ç”¨çµ±è¨ˆ")
    print("=" * 60)
    
    import psutil
    process = psutil.Process()
    memory_info = process.memory_info()
    
    print(f"  RSS (å¸¸é§è¨˜æ†¶é«”): {memory_info.rss / 1024 / 1024:.1f} MB")
    print(f"  VMS (è™›æ“¬è¨˜æ†¶é«”): {memory_info.vms / 1024 / 1024:.1f} MB")

if __name__ == "__main__":
    try:
        test_embedding_model()
        test_reranker_model()
        test_memory_usage()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        print("=" * 60)
        print("\nâš ï¸  æ³¨æ„äº‹é …:")
        print("1. ç”±æ–¼æ›´æ›äº† Embedding æ¨¡å‹ï¼Œéœ€è¦é‡æ–°å‘é‡åŒ–æ‰€æœ‰æ–‡æª”")
        print("2. éœ€è¦æ¸…ç©ºä¸¦é‡å»º ChromaDB å‘é‡è³‡æ–™åº«")
        print("3. é‡å•Ÿå¾Œç«¯æœå‹™ä»¥è¼‰å…¥æ–°é…ç½®")
        
    except Exception as e:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
