"""æª¢æŸ¥ AI åˆ†å¡Šç²’åº¦æ˜¯å¦åˆç†"""
import asyncio
import aiohttp
import os
from dotenv import load_dotenv

load_dotenv('.env', override=True)

async def main():
    api_url = os.getenv('API_URL', 'http://localhost:8000')
    username = os.getenv('USERNAME')
    password = os.getenv('PASSWORD')
    
    async with aiohttp.ClientSession() as session:
        # ç™»å…¥
        login_resp = await session.post(
            f'{api_url}/api/v1/auth/token', 
            data={'username': username, 'password': password}
        )
        login_data = await login_resp.json()
        
        if 'access_token' not in login_data:
            print(f"ç™»å…¥å¤±æ•—: {login_data}")
            return
        
        token = login_data['access_token']
        headers = {'Authorization': f'Bearer {token}'}
        
        # ç²å–æ–‡æª”åˆ—è¡¨
        docs_resp = await session.get(
            f'{api_url}/api/v1/documents/',
            headers=headers,
            params={'limit': 20}
        )
        docs_data = await docs_resp.json()
        documents = docs_data.get('items', [])
        
        print(f"åˆ†æ {len(documents)} å€‹æ–‡æª”çš„åˆ†å¡Šç²’åº¦")
        print("=" * 80)
        
        # çµ±è¨ˆ
        total_chunks = 0
        total_docs_with_chunks = 0
        chunk_lengths = []
        chunk_types = {}
        strategy_counts = {"hybrid": 0, "raw_only": 0, "sub_chunked": 0}
        
        for doc in documents:
            doc_id = doc.get('id')
            filename = doc.get('filename', 'unknown')
            extracted_text = doc.get('extracted_text', '')
            
            # ç²å– logical_chunks
            analysis = doc.get('analysis', {})
            ai_output = analysis.get('ai_analysis_output', {}) or {}
            logical_chunks = ai_output.get('logical_chunks', [])
            
            if not logical_chunks:
                continue
            
            total_docs_with_chunks += 1
            
            print(f"\nğŸ“„ {filename[:50]}")
            print(f"   æ–‡æª”é•·åº¦: {len(extracted_text)} å­—ç¬¦")
            print(f"   åˆ†å¡Šæ•¸é‡: {len(logical_chunks)} å€‹")
            
            if len(extracted_text) > 0:
                avg_chunk_size = len(extracted_text) / len(logical_chunks)
                print(f"   å¹³å‡å¡Šå¤§å°: {avg_chunk_size:.0f} å­—ç¬¦")
            
            for i, chunk in enumerate(logical_chunks):
                chunk_type = chunk.get('type', 'unknown')
                start_id = chunk.get('start_id', '')
                end_id = chunk.get('end_id', '')
                summary = chunk.get('summary', '')
                
                # çµ±è¨ˆé¡å‹
                chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
                total_chunks += 1
                
                # è¨ˆç®—è¡Œæ•¸
                try:
                    start_num = int(start_id.replace('L', ''))
                    end_num = int(end_id.replace('L', ''))
                    line_count = end_num - start_num + 1
                except:
                    line_count = 0
                
                # åˆ¤æ–·å‘é‡åŒ–ç­–ç•¥
                # å‡è¨­æ¯è¡Œç´„ 30 å­—ç¬¦
                estimated_length = line_count * 30
                if estimated_length <= 350:
                    strategy = "hybrid"
                elif estimated_length <= 480:
                    strategy = "raw_only"
                else:
                    strategy = "sub_chunked"
                strategy_counts[strategy] += 1
                
                chunk_lengths.append(line_count)
                
                print(f"   [{i+1}] {chunk_type:12} | {start_id}-{end_id} ({line_count:2} è¡Œ) | {summary[:40]}...")
        
        # ç¸½çµçµ±è¨ˆ
        print("\n" + "=" * 80)
        print("ğŸ“Š åˆ†å¡Šç²’åº¦çµ±è¨ˆ")
        print("=" * 80)
        
        print(f"\næ–‡æª”çµ±è¨ˆ:")
        print(f"   æœ‰åˆ†å¡Šçš„æ–‡æª”: {total_docs_with_chunks}")
        print(f"   ç¸½åˆ†å¡Šæ•¸: {total_chunks}")
        if total_docs_with_chunks > 0:
            print(f"   å¹³å‡æ¯æ–‡æª”åˆ†å¡Šæ•¸: {total_chunks / total_docs_with_chunks:.1f}")
        
        print(f"\nåˆ†å¡Šé¡å‹åˆ†å¸ƒ:")
        for chunk_type, count in sorted(chunk_types.items(), key=lambda x: -x[1]):
            pct = count / total_chunks * 100 if total_chunks > 0 else 0
            print(f"   {chunk_type:15}: {count:3} ({pct:.1f}%)")
        
        print(f"\nå‘é‡åŒ–ç­–ç•¥åˆ†å¸ƒ (ä¼°ç®—):")
        for strategy, count in strategy_counts.items():
            pct = count / total_chunks * 100 if total_chunks > 0 else 0
            print(f"   {strategy:15}: {count:3} ({pct:.1f}%)")
        
        if chunk_lengths:
            print(f"\nåˆ†å¡Šè¡Œæ•¸çµ±è¨ˆ:")
            print(f"   æœ€å°: {min(chunk_lengths)} è¡Œ")
            print(f"   æœ€å¤§: {max(chunk_lengths)} è¡Œ")
            print(f"   å¹³å‡: {sum(chunk_lengths) / len(chunk_lengths):.1f} è¡Œ")
            print(f"   ä¸­ä½æ•¸: {sorted(chunk_lengths)[len(chunk_lengths)//2]} è¡Œ")
            
            # è¡Œæ•¸åˆ†å¸ƒ
            print(f"\nè¡Œæ•¸åˆ†å¸ƒ:")
            ranges = [(1, 5), (6, 10), (11, 20), (21, 30), (31, 50), (51, 100), (101, 999)]
            for low, high in ranges:
                count = sum(1 for l in chunk_lengths if low <= l <= high)
                if count > 0:
                    pct = count / len(chunk_lengths) * 100
                    print(f"   {low:3}-{high:3} è¡Œ: {count:3} ({pct:.1f}%)")

if __name__ == "__main__":
    asyncio.run(main())
